{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168af976",
   "metadata": {},
   "source": [
    "# PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c2631e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1797e290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv('forestfires.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6b017",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec0fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.iloc[:,2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4575aa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FFMC   DMC     DC  ISI  temp  RH  wind  rain  area  dayfri  ...  monthfeb  \\\n",
       "0  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0       1  ...         0   \n",
       "1  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0       0  ...         0   \n",
       "2  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0       0  ...         0   \n",
       "3  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0       1  ...         0   \n",
       "4  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0       0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026849fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['size_category']=data1['size_category'].astype('category')\n",
    "data1['size_category']=data1['size_category'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abda20bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_category  \n",
       "0           0         0              1  \n",
       "1           1         0              1  \n",
       "2           1         0              1  \n",
       "3           0         0              1  \n",
       "4           0         0              1  \n",
       "..        ...       ...            ...  \n",
       "512         0         0              0  \n",
       "513         0         0              0  \n",
       "514         0         0              0  \n",
       "515         0         0              1  \n",
       "516         0         0              1  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d86565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc99324f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "      <td>0.731141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "      <td>0.443796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthfeb  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.038685   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.193029   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthjan    monthjul    monthjun    monthmar    monthmay    monthnov  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.003868    0.061896    0.032882    0.104449    0.003868    0.001934   \n",
       "std      0.062137    0.241199    0.178500    0.306138    0.062137    0.043980   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthoct    monthsep  size_category  \n",
       "count  517.000000  517.000000     517.000000  \n",
       "mean     0.029014    0.332689       0.731141  \n",
       "std      0.168007    0.471632       0.443796  \n",
       "min      0.000000    0.000000       0.000000  \n",
       "25%      0.000000    0.000000       0.000000  \n",
       "50%      0.000000    0.000000       1.000000  \n",
       "75%      0.000000    1.000000       1.000000  \n",
       "max      1.000000    1.000000       1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "515091ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 29 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   FFMC           517 non-null    float64\n",
      " 1   DMC            517 non-null    float64\n",
      " 2   DC             517 non-null    float64\n",
      " 3   ISI            517 non-null    float64\n",
      " 4   temp           517 non-null    float64\n",
      " 5   RH             517 non-null    int64  \n",
      " 6   wind           517 non-null    float64\n",
      " 7   rain           517 non-null    float64\n",
      " 8   area           517 non-null    float64\n",
      " 9   dayfri         517 non-null    int64  \n",
      " 10  daymon         517 non-null    int64  \n",
      " 11  daysat         517 non-null    int64  \n",
      " 12  daysun         517 non-null    int64  \n",
      " 13  daythu         517 non-null    int64  \n",
      " 14  daytue         517 non-null    int64  \n",
      " 15  daywed         517 non-null    int64  \n",
      " 16  monthapr       517 non-null    int64  \n",
      " 17  monthaug       517 non-null    int64  \n",
      " 18  monthdec       517 non-null    int64  \n",
      " 19  monthfeb       517 non-null    int64  \n",
      " 20  monthjan       517 non-null    int64  \n",
      " 21  monthjul       517 non-null    int64  \n",
      " 22  monthjun       517 non-null    int64  \n",
      " 23  monthmar       517 non-null    int64  \n",
      " 24  monthmay       517 non-null    int64  \n",
      " 25  monthnov       517 non-null    int64  \n",
      " 26  monthoct       517 non-null    int64  \n",
      " 27  monthsep       517 non-null    int64  \n",
      " 28  size_category  517 non-null    int8   \n",
      "dtypes: float64(8), int64(20), int8(1)\n",
      "memory usage: 113.7 KB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "855be35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFMC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382619</td>\n",
       "      <td>0.330512</td>\n",
       "      <td>0.531805</td>\n",
       "      <td>0.431532</td>\n",
       "      <td>-0.300995</td>\n",
       "      <td>-0.028485</td>\n",
       "      <td>0.056702</td>\n",
       "      <td>0.040122</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281535</td>\n",
       "      <td>-0.454771</td>\n",
       "      <td>0.031833</td>\n",
       "      <td>-0.040634</td>\n",
       "      <td>-0.074327</td>\n",
       "      <td>-0.037230</td>\n",
       "      <td>-0.088964</td>\n",
       "      <td>-0.005998</td>\n",
       "      <td>0.076609</td>\n",
       "      <td>-0.022063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMC</th>\n",
       "      <td>0.382619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682192</td>\n",
       "      <td>0.305128</td>\n",
       "      <td>0.469594</td>\n",
       "      <td>0.073795</td>\n",
       "      <td>-0.105342</td>\n",
       "      <td>0.074790</td>\n",
       "      <td>0.072994</td>\n",
       "      <td>-0.012010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317899</td>\n",
       "      <td>-0.105647</td>\n",
       "      <td>-0.001946</td>\n",
       "      <td>-0.050403</td>\n",
       "      <td>-0.407404</td>\n",
       "      <td>-0.081980</td>\n",
       "      <td>-0.074218</td>\n",
       "      <td>-0.187632</td>\n",
       "      <td>0.110907</td>\n",
       "      <td>-0.034715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>0.330512</td>\n",
       "      <td>0.682192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>0.496208</td>\n",
       "      <td>-0.039192</td>\n",
       "      <td>-0.203466</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399277</td>\n",
       "      <td>-0.115064</td>\n",
       "      <td>-0.100887</td>\n",
       "      <td>-0.186183</td>\n",
       "      <td>-0.650427</td>\n",
       "      <td>-0.114209</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>0.093279</td>\n",
       "      <td>0.531857</td>\n",
       "      <td>-0.019428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISI</th>\n",
       "      <td>0.531805</td>\n",
       "      <td>0.305128</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.394287</td>\n",
       "      <td>-0.132517</td>\n",
       "      <td>0.106826</td>\n",
       "      <td>0.067668</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.046695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249777</td>\n",
       "      <td>-0.103588</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.111516</td>\n",
       "      <td>-0.143520</td>\n",
       "      <td>-0.060493</td>\n",
       "      <td>-0.076559</td>\n",
       "      <td>-0.071154</td>\n",
       "      <td>-0.068877</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.431532</td>\n",
       "      <td>0.469594</td>\n",
       "      <td>0.496208</td>\n",
       "      <td>0.394287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.527390</td>\n",
       "      <td>-0.227116</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>-0.071949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320015</td>\n",
       "      <td>-0.146520</td>\n",
       "      <td>0.142588</td>\n",
       "      <td>0.051015</td>\n",
       "      <td>-0.341797</td>\n",
       "      <td>-0.045540</td>\n",
       "      <td>-0.053798</td>\n",
       "      <td>-0.053513</td>\n",
       "      <td>0.088006</td>\n",
       "      <td>-0.006021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>-0.300995</td>\n",
       "      <td>0.073795</td>\n",
       "      <td>-0.039192</td>\n",
       "      <td>-0.132517</td>\n",
       "      <td>-0.527390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069410</td>\n",
       "      <td>0.099751</td>\n",
       "      <td>-0.075519</td>\n",
       "      <td>0.064506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140430</td>\n",
       "      <td>0.170923</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>-0.089836</td>\n",
       "      <td>0.086822</td>\n",
       "      <td>-0.035885</td>\n",
       "      <td>-0.072334</td>\n",
       "      <td>-0.062596</td>\n",
       "      <td>0.045243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>-0.028485</td>\n",
       "      <td>-0.105342</td>\n",
       "      <td>-0.203466</td>\n",
       "      <td>0.106826</td>\n",
       "      <td>-0.227116</td>\n",
       "      <td>0.069410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061119</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.118090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029431</td>\n",
       "      <td>-0.070245</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.181433</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>-0.053850</td>\n",
       "      <td>-0.181476</td>\n",
       "      <td>-0.059113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain</th>\n",
       "      <td>0.056702</td>\n",
       "      <td>0.074790</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>0.067668</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.099751</td>\n",
       "      <td>0.061119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007366</td>\n",
       "      <td>-0.004261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014698</td>\n",
       "      <td>-0.004566</td>\n",
       "      <td>-0.013390</td>\n",
       "      <td>-0.013510</td>\n",
       "      <td>-0.020744</td>\n",
       "      <td>-0.004566</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>-0.012665</td>\n",
       "      <td>-0.051733</td>\n",
       "      <td>-0.050001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>0.040122</td>\n",
       "      <td>0.072994</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>-0.075519</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>-0.007366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020732</td>\n",
       "      <td>-0.012589</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>-0.020314</td>\n",
       "      <td>-0.045596</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>-0.008893</td>\n",
       "      <td>-0.016878</td>\n",
       "      <td>0.056573</td>\n",
       "      <td>-0.311322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayfri</th>\n",
       "      <td>0.019306</td>\n",
       "      <td>-0.012010</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.046695</td>\n",
       "      <td>-0.071949</td>\n",
       "      <td>0.064506</td>\n",
       "      <td>0.118090</td>\n",
       "      <td>-0.004261</td>\n",
       "      <td>-0.052911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046323</td>\n",
       "      <td>-0.027643</td>\n",
       "      <td>-0.048969</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.036205</td>\n",
       "      <td>0.056423</td>\n",
       "      <td>-0.019527</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0.107671</td>\n",
       "      <td>0.021810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daymon</th>\n",
       "      <td>-0.059396</td>\n",
       "      <td>-0.107921</td>\n",
       "      <td>-0.052993</td>\n",
       "      <td>-0.158601</td>\n",
       "      <td>-0.136529</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>-0.063881</td>\n",
       "      <td>-0.029945</td>\n",
       "      <td>-0.021206</td>\n",
       "      <td>-0.181293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>-0.025470</td>\n",
       "      <td>-0.013300</td>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.077125</td>\n",
       "      <td>-0.025470</td>\n",
       "      <td>-0.017992</td>\n",
       "      <td>0.060975</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.011156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysat</th>\n",
       "      <td>-0.019637</td>\n",
       "      <td>-0.003653</td>\n",
       "      <td>-0.035189</td>\n",
       "      <td>-0.038585</td>\n",
       "      <td>0.034899</td>\n",
       "      <td>-0.023869</td>\n",
       "      <td>-0.063799</td>\n",
       "      <td>-0.032271</td>\n",
       "      <td>0.087868</td>\n",
       "      <td>-0.195372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.060945</td>\n",
       "      <td>-0.022408</td>\n",
       "      <td>0.021024</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>-0.019390</td>\n",
       "      <td>0.017584</td>\n",
       "      <td>-0.032783</td>\n",
       "      <td>-0.040397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysun</th>\n",
       "      <td>-0.089517</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>-0.003243</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.136220</td>\n",
       "      <td>0.027981</td>\n",
       "      <td>-0.017872</td>\n",
       "      <td>-0.020463</td>\n",
       "      <td>-0.210462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.050887</td>\n",
       "      <td>-0.018241</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>-0.047726</td>\n",
       "      <td>-0.029568</td>\n",
       "      <td>-0.020887</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>-0.048817</td>\n",
       "      <td>-0.016429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daythu</th>\n",
       "      <td>0.071730</td>\n",
       "      <td>0.087672</td>\n",
       "      <td>0.051859</td>\n",
       "      <td>-0.022406</td>\n",
       "      <td>0.051432</td>\n",
       "      <td>-0.123061</td>\n",
       "      <td>-0.062553</td>\n",
       "      <td>-0.026798</td>\n",
       "      <td>0.020121</td>\n",
       "      <td>-0.162237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042278</td>\n",
       "      <td>-0.022793</td>\n",
       "      <td>-0.019300</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>-0.026885</td>\n",
       "      <td>-0.022793</td>\n",
       "      <td>-0.016101</td>\n",
       "      <td>-0.063223</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.045985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytue</th>\n",
       "      <td>0.011225</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.028368</td>\n",
       "      <td>0.068610</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>-0.014211</td>\n",
       "      <td>0.053396</td>\n",
       "      <td>0.139311</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>-0.166728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014491</td>\n",
       "      <td>-0.023424</td>\n",
       "      <td>0.049688</td>\n",
       "      <td>-0.069308</td>\n",
       "      <td>-0.032351</td>\n",
       "      <td>-0.023424</td>\n",
       "      <td>0.117121</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>-0.028570</td>\n",
       "      <td>-0.036998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daywed</th>\n",
       "      <td>0.093908</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>0.024803</td>\n",
       "      <td>0.125415</td>\n",
       "      <td>0.090580</td>\n",
       "      <td>-0.087508</td>\n",
       "      <td>-0.019965</td>\n",
       "      <td>-0.020744</td>\n",
       "      <td>-0.011452</td>\n",
       "      <td>-0.151487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035713</td>\n",
       "      <td>-0.021282</td>\n",
       "      <td>-0.008985</td>\n",
       "      <td>0.043422</td>\n",
       "      <td>-0.033917</td>\n",
       "      <td>-0.021282</td>\n",
       "      <td>-0.015034</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>-0.053222</td>\n",
       "      <td>0.021659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthapr</th>\n",
       "      <td>-0.117199</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.268211</td>\n",
       "      <td>-0.106478</td>\n",
       "      <td>-0.157051</td>\n",
       "      <td>0.021235</td>\n",
       "      <td>0.048266</td>\n",
       "      <td>-0.009752</td>\n",
       "      <td>-0.008280</td>\n",
       "      <td>-0.019140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026701</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>-0.034190</td>\n",
       "      <td>-0.024543</td>\n",
       "      <td>-0.045456</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>-0.005860</td>\n",
       "      <td>-0.023008</td>\n",
       "      <td>-0.093982</td>\n",
       "      <td>0.014001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthaug</th>\n",
       "      <td>0.228103</td>\n",
       "      <td>0.497928</td>\n",
       "      <td>0.279361</td>\n",
       "      <td>0.334639</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.028577</td>\n",
       "      <td>0.093101</td>\n",
       "      <td>-0.004187</td>\n",
       "      <td>-0.100837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149116</td>\n",
       "      <td>-0.046323</td>\n",
       "      <td>-0.190937</td>\n",
       "      <td>-0.137065</td>\n",
       "      <td>-0.253859</td>\n",
       "      <td>-0.046323</td>\n",
       "      <td>-0.032724</td>\n",
       "      <td>-0.128493</td>\n",
       "      <td>-0.524858</td>\n",
       "      <td>0.058954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthdec</th>\n",
       "      <td>-0.137044</td>\n",
       "      <td>-0.176301</td>\n",
       "      <td>-0.105642</td>\n",
       "      <td>-0.162322</td>\n",
       "      <td>-0.329648</td>\n",
       "      <td>-0.047714</td>\n",
       "      <td>0.269702</td>\n",
       "      <td>-0.009752</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>-0.019140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026701</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>-0.034190</td>\n",
       "      <td>-0.024543</td>\n",
       "      <td>-0.045456</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>-0.005860</td>\n",
       "      <td>-0.023008</td>\n",
       "      <td>-0.093982</td>\n",
       "      <td>-0.186140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthfeb</th>\n",
       "      <td>-0.281535</td>\n",
       "      <td>-0.317899</td>\n",
       "      <td>-0.399277</td>\n",
       "      <td>-0.249777</td>\n",
       "      <td>-0.320015</td>\n",
       "      <td>0.140430</td>\n",
       "      <td>-0.029431</td>\n",
       "      <td>-0.014698</td>\n",
       "      <td>-0.020732</td>\n",
       "      <td>0.046323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012501</td>\n",
       "      <td>-0.051528</td>\n",
       "      <td>-0.036989</td>\n",
       "      <td>-0.068508</td>\n",
       "      <td>-0.012501</td>\n",
       "      <td>-0.008831</td>\n",
       "      <td>-0.034676</td>\n",
       "      <td>-0.141642</td>\n",
       "      <td>-0.014090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthjan</th>\n",
       "      <td>-0.454771</td>\n",
       "      <td>-0.105647</td>\n",
       "      <td>-0.115064</td>\n",
       "      <td>-0.103588</td>\n",
       "      <td>-0.146520</td>\n",
       "      <td>0.170923</td>\n",
       "      <td>-0.070245</td>\n",
       "      <td>-0.004566</td>\n",
       "      <td>-0.012589</td>\n",
       "      <td>-0.027643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016007</td>\n",
       "      <td>-0.011491</td>\n",
       "      <td>-0.021282</td>\n",
       "      <td>-0.003883</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>-0.010772</td>\n",
       "      <td>-0.044001</td>\n",
       "      <td>0.037790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthjul</th>\n",
       "      <td>0.031833</td>\n",
       "      <td>-0.001946</td>\n",
       "      <td>-0.100887</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.142588</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.013390</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>-0.048969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051528</td>\n",
       "      <td>-0.016007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047363</td>\n",
       "      <td>-0.087722</td>\n",
       "      <td>-0.016007</td>\n",
       "      <td>-0.011308</td>\n",
       "      <td>-0.044402</td>\n",
       "      <td>-0.181367</td>\n",
       "      <td>-0.007179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthjun</th>\n",
       "      <td>-0.040634</td>\n",
       "      <td>-0.050403</td>\n",
       "      <td>-0.186183</td>\n",
       "      <td>0.111516</td>\n",
       "      <td>0.051015</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>-0.013510</td>\n",
       "      <td>-0.020314</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036989</td>\n",
       "      <td>-0.011491</td>\n",
       "      <td>-0.047363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062972</td>\n",
       "      <td>-0.011491</td>\n",
       "      <td>-0.008117</td>\n",
       "      <td>-0.031874</td>\n",
       "      <td>-0.130195</td>\n",
       "      <td>0.038423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthmar</th>\n",
       "      <td>-0.074327</td>\n",
       "      <td>-0.407404</td>\n",
       "      <td>-0.650427</td>\n",
       "      <td>-0.143520</td>\n",
       "      <td>-0.341797</td>\n",
       "      <td>-0.089836</td>\n",
       "      <td>0.181433</td>\n",
       "      <td>-0.020744</td>\n",
       "      <td>-0.045596</td>\n",
       "      <td>0.036205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068508</td>\n",
       "      <td>-0.021282</td>\n",
       "      <td>-0.087722</td>\n",
       "      <td>-0.062972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021282</td>\n",
       "      <td>-0.015034</td>\n",
       "      <td>-0.059034</td>\n",
       "      <td>-0.241135</td>\n",
       "      <td>0.035923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthmay</th>\n",
       "      <td>-0.037230</td>\n",
       "      <td>-0.081980</td>\n",
       "      <td>-0.114209</td>\n",
       "      <td>-0.060493</td>\n",
       "      <td>-0.045540</td>\n",
       "      <td>0.086822</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>-0.004566</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.056423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012501</td>\n",
       "      <td>-0.003883</td>\n",
       "      <td>-0.016007</td>\n",
       "      <td>-0.011491</td>\n",
       "      <td>-0.021282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>-0.010772</td>\n",
       "      <td>-0.044001</td>\n",
       "      <td>-0.032488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthnov</th>\n",
       "      <td>-0.088964</td>\n",
       "      <td>-0.074218</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.076559</td>\n",
       "      <td>-0.053798</td>\n",
       "      <td>-0.035885</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>-0.008893</td>\n",
       "      <td>-0.019527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008831</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>-0.011308</td>\n",
       "      <td>-0.008117</td>\n",
       "      <td>-0.015034</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007610</td>\n",
       "      <td>-0.031083</td>\n",
       "      <td>0.026695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthoct</th>\n",
       "      <td>-0.005998</td>\n",
       "      <td>-0.187632</td>\n",
       "      <td>0.093279</td>\n",
       "      <td>-0.071154</td>\n",
       "      <td>-0.053513</td>\n",
       "      <td>-0.072334</td>\n",
       "      <td>-0.053850</td>\n",
       "      <td>-0.012665</td>\n",
       "      <td>-0.016878</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034676</td>\n",
       "      <td>-0.010772</td>\n",
       "      <td>-0.044402</td>\n",
       "      <td>-0.031874</td>\n",
       "      <td>-0.059034</td>\n",
       "      <td>-0.010772</td>\n",
       "      <td>-0.007610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthsep</th>\n",
       "      <td>0.076609</td>\n",
       "      <td>0.110907</td>\n",
       "      <td>0.531857</td>\n",
       "      <td>-0.068877</td>\n",
       "      <td>0.088006</td>\n",
       "      <td>-0.062596</td>\n",
       "      <td>-0.181476</td>\n",
       "      <td>-0.051733</td>\n",
       "      <td>0.056573</td>\n",
       "      <td>0.107671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141642</td>\n",
       "      <td>-0.044001</td>\n",
       "      <td>-0.181367</td>\n",
       "      <td>-0.130195</td>\n",
       "      <td>-0.241135</td>\n",
       "      <td>-0.044001</td>\n",
       "      <td>-0.031083</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_category</th>\n",
       "      <td>-0.022063</td>\n",
       "      <td>-0.034715</td>\n",
       "      <td>-0.019428</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>0.045243</td>\n",
       "      <td>-0.059113</td>\n",
       "      <td>-0.050001</td>\n",
       "      <td>-0.311322</td>\n",
       "      <td>0.021810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014090</td>\n",
       "      <td>0.037790</td>\n",
       "      <td>-0.007179</td>\n",
       "      <td>0.038423</td>\n",
       "      <td>0.035923</td>\n",
       "      <td>-0.032488</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>-0.044038</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   FFMC       DMC        DC       ISI      temp        RH  \\\n",
       "FFMC           1.000000  0.382619  0.330512  0.531805  0.431532 -0.300995   \n",
       "DMC            0.382619  1.000000  0.682192  0.305128  0.469594  0.073795   \n",
       "DC             0.330512  0.682192  1.000000  0.229154  0.496208 -0.039192   \n",
       "ISI            0.531805  0.305128  0.229154  1.000000  0.394287 -0.132517   \n",
       "temp           0.431532  0.469594  0.496208  0.394287  1.000000 -0.527390   \n",
       "RH            -0.300995  0.073795 -0.039192 -0.132517 -0.527390  1.000000   \n",
       "wind          -0.028485 -0.105342 -0.203466  0.106826 -0.227116  0.069410   \n",
       "rain           0.056702  0.074790  0.035861  0.067668  0.069491  0.099751   \n",
       "area           0.040122  0.072994  0.049383  0.008258  0.097844 -0.075519   \n",
       "dayfri         0.019306 -0.012010 -0.004220  0.046695 -0.071949  0.064506   \n",
       "daymon        -0.059396 -0.107921 -0.052993 -0.158601 -0.136529  0.009376   \n",
       "daysat        -0.019637 -0.003653 -0.035189 -0.038585  0.034899 -0.023869   \n",
       "daysun        -0.089517  0.025355 -0.001431 -0.003243  0.014403  0.136220   \n",
       "daythu         0.071730  0.087672  0.051859 -0.022406  0.051432 -0.123061   \n",
       "daytue         0.011225  0.000016  0.028368  0.068610  0.035630 -0.014211   \n",
       "daywed         0.093908  0.017939  0.024803  0.125415  0.090580 -0.087508   \n",
       "monthapr      -0.117199 -0.197543 -0.268211 -0.106478 -0.157051  0.021235   \n",
       "monthaug       0.228103  0.497928  0.279361  0.334639  0.351404  0.054761   \n",
       "monthdec      -0.137044 -0.176301 -0.105642 -0.162322 -0.329648 -0.047714   \n",
       "monthfeb      -0.281535 -0.317899 -0.399277 -0.249777 -0.320015  0.140430   \n",
       "monthjan      -0.454771 -0.105647 -0.115064 -0.103588 -0.146520  0.170923   \n",
       "monthjul       0.031833 -0.001946 -0.100887  0.020982  0.142588  0.013185   \n",
       "monthjun      -0.040634 -0.050403 -0.186183  0.111516  0.051015  0.009382   \n",
       "monthmar      -0.074327 -0.407404 -0.650427 -0.143520 -0.341797 -0.089836   \n",
       "monthmay      -0.037230 -0.081980 -0.114209 -0.060493 -0.045540  0.086822   \n",
       "monthnov      -0.088964 -0.074218 -0.078380 -0.076559 -0.053798 -0.035885   \n",
       "monthoct      -0.005998 -0.187632  0.093279 -0.071154 -0.053513 -0.072334   \n",
       "monthsep       0.076609  0.110907  0.531857 -0.068877  0.088006 -0.062596   \n",
       "size_category -0.022063 -0.034715 -0.019428  0.008726 -0.006021  0.045243   \n",
       "\n",
       "                   wind      rain      area    dayfri  ...  monthfeb  \\\n",
       "FFMC          -0.028485  0.056702  0.040122  0.019306  ... -0.281535   \n",
       "DMC           -0.105342  0.074790  0.072994 -0.012010  ... -0.317899   \n",
       "DC            -0.203466  0.035861  0.049383 -0.004220  ... -0.399277   \n",
       "ISI            0.106826  0.067668  0.008258  0.046695  ... -0.249777   \n",
       "temp          -0.227116  0.069491  0.097844 -0.071949  ... -0.320015   \n",
       "RH             0.069410  0.099751 -0.075519  0.064506  ...  0.140430   \n",
       "wind           1.000000  0.061119  0.012317  0.118090  ... -0.029431   \n",
       "rain           0.061119  1.000000 -0.007366 -0.004261  ... -0.014698   \n",
       "area           0.012317 -0.007366  1.000000 -0.052911  ... -0.020732   \n",
       "dayfri         0.118090 -0.004261 -0.052911  1.000000  ...  0.046323   \n",
       "daymon        -0.063881 -0.029945 -0.021206 -0.181293  ...  0.003933   \n",
       "daysat        -0.063799 -0.032271  0.087868 -0.195372  ...  0.020406   \n",
       "daysun         0.027981 -0.017872 -0.020463 -0.210462  ...  0.008416   \n",
       "daythu        -0.062553 -0.026798  0.020121 -0.162237  ... -0.042278   \n",
       "daytue         0.053396  0.139311 -0.001333 -0.166728  ... -0.014491   \n",
       "daywed        -0.019965 -0.020744 -0.011452 -0.151487  ... -0.035713   \n",
       "monthapr       0.048266 -0.009752 -0.008280 -0.019140  ... -0.026701   \n",
       "monthaug       0.028577  0.093101 -0.004187 -0.100837  ... -0.149116   \n",
       "monthdec       0.269702 -0.009752  0.001010 -0.019140  ... -0.026701   \n",
       "monthfeb      -0.029431 -0.014698 -0.020732  0.046323  ...  1.000000   \n",
       "monthjan      -0.070245 -0.004566 -0.012589 -0.027643  ... -0.012501   \n",
       "monthjul      -0.040645 -0.013390  0.006149 -0.048969  ... -0.051528   \n",
       "monthjun       0.012124 -0.013510 -0.020314  0.006000  ... -0.036989   \n",
       "monthmar       0.181433 -0.020744 -0.045596  0.036205  ... -0.068508   \n",
       "monthmay       0.015054 -0.004566  0.006264  0.056423  ... -0.012501   \n",
       "monthnov       0.011864 -0.003225 -0.008893 -0.019527  ... -0.008831   \n",
       "monthoct      -0.053850 -0.012665 -0.016878 -0.045585  ... -0.034676   \n",
       "monthsep      -0.181476 -0.051733  0.056573  0.107671  ... -0.141642   \n",
       "size_category -0.059113 -0.050001 -0.311322  0.021810  ... -0.014090   \n",
       "\n",
       "               monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "FFMC          -0.454771  0.031833 -0.040634 -0.074327 -0.037230 -0.088964   \n",
       "DMC           -0.105647 -0.001946 -0.050403 -0.407404 -0.081980 -0.074218   \n",
       "DC            -0.115064 -0.100887 -0.186183 -0.650427 -0.114209 -0.078380   \n",
       "ISI           -0.103588  0.020982  0.111516 -0.143520 -0.060493 -0.076559   \n",
       "temp          -0.146520  0.142588  0.051015 -0.341797 -0.045540 -0.053798   \n",
       "RH             0.170923  0.013185  0.009382 -0.089836  0.086822 -0.035885   \n",
       "wind          -0.070245 -0.040645  0.012124  0.181433  0.015054  0.011864   \n",
       "rain          -0.004566 -0.013390 -0.013510 -0.020744 -0.004566 -0.003225   \n",
       "area          -0.012589  0.006149 -0.020314 -0.045596  0.006264 -0.008893   \n",
       "dayfri        -0.027643 -0.048969  0.006000  0.036205  0.056423 -0.019527   \n",
       "daymon        -0.025470 -0.013300  0.017553  0.077125 -0.025470 -0.017992   \n",
       "daysat         0.057019  0.060945 -0.022408  0.021024  0.057019 -0.019390   \n",
       "daysun         0.050887 -0.018241  0.024540 -0.047726 -0.029568 -0.020887   \n",
       "daythu        -0.022793 -0.019300 -0.000195 -0.026885 -0.022793 -0.016101   \n",
       "daytue        -0.023424  0.049688 -0.069308 -0.032351 -0.023424  0.117121   \n",
       "daywed        -0.021282 -0.008985  0.043422 -0.033917 -0.021282 -0.015034   \n",
       "monthapr      -0.008295 -0.034190 -0.024543 -0.045456 -0.008295 -0.005860   \n",
       "monthaug      -0.046323 -0.190937 -0.137065 -0.253859 -0.046323 -0.032724   \n",
       "monthdec      -0.008295 -0.034190 -0.024543 -0.045456 -0.008295 -0.005860   \n",
       "monthfeb      -0.012501 -0.051528 -0.036989 -0.068508 -0.012501 -0.008831   \n",
       "monthjan       1.000000 -0.016007 -0.011491 -0.021282 -0.003883 -0.002743   \n",
       "monthjul      -0.016007  1.000000 -0.047363 -0.087722 -0.016007 -0.011308   \n",
       "monthjun      -0.011491 -0.047363  1.000000 -0.062972 -0.011491 -0.008117   \n",
       "monthmar      -0.021282 -0.087722 -0.062972  1.000000 -0.021282 -0.015034   \n",
       "monthmay      -0.003883 -0.016007 -0.011491 -0.021282  1.000000 -0.002743   \n",
       "monthnov      -0.002743 -0.011308 -0.008117 -0.015034 -0.002743  1.000000   \n",
       "monthoct      -0.010772 -0.044402 -0.031874 -0.059034 -0.010772 -0.007610   \n",
       "monthsep      -0.044001 -0.181367 -0.130195 -0.241135 -0.044001 -0.031083   \n",
       "size_category  0.037790 -0.007179  0.038423  0.035923 -0.032488  0.026695   \n",
       "\n",
       "               monthoct  monthsep  size_category  \n",
       "FFMC          -0.005998  0.076609      -0.022063  \n",
       "DMC           -0.187632  0.110907      -0.034715  \n",
       "DC             0.093279  0.531857      -0.019428  \n",
       "ISI           -0.071154 -0.068877       0.008726  \n",
       "temp          -0.053513  0.088006      -0.006021  \n",
       "RH            -0.072334 -0.062596       0.045243  \n",
       "wind          -0.053850 -0.181476      -0.059113  \n",
       "rain          -0.012665 -0.051733      -0.050001  \n",
       "area          -0.016878  0.056573      -0.311322  \n",
       "dayfri        -0.045585  0.107671       0.021810  \n",
       "daymon         0.060975  0.039632       0.011156  \n",
       "daysat         0.017584 -0.032783      -0.040397  \n",
       "daysun         0.007252 -0.048817      -0.016429  \n",
       "daythu        -0.063223  0.008984       0.045985  \n",
       "daytue         0.005008 -0.028570      -0.036998  \n",
       "daywed         0.016325 -0.053222       0.021659  \n",
       "monthapr      -0.023008 -0.093982       0.014001  \n",
       "monthaug      -0.128493 -0.524858       0.058954  \n",
       "monthdec      -0.023008 -0.093982      -0.186140  \n",
       "monthfeb      -0.034676 -0.141642      -0.014090  \n",
       "monthjan      -0.010772 -0.044001       0.037790  \n",
       "monthjul      -0.044402 -0.181367      -0.007179  \n",
       "monthjun      -0.031874 -0.130195       0.038423  \n",
       "monthmar      -0.059034 -0.241135       0.035923  \n",
       "monthmay      -0.010772 -0.044001      -0.032488  \n",
       "monthnov      -0.007610 -0.031083       0.026695  \n",
       "monthoct       1.000000 -0.122053       0.000855  \n",
       "monthsep      -0.122053  1.000000      -0.044038  \n",
       "size_category  0.000855 -0.044038       1.000000  \n",
       "\n",
       "[29 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlation matrices\n",
    "data1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e7d697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data converting(array format)\n",
    "data2=data1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc56cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spilt into input x and y output\n",
    "x= data2[:,0:28]\n",
    "y=data2[:,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7838fda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86.2,  26.2,  94.3, ...,   0. ,   0. ,   0. ],\n",
       "       [ 90.6,  35.4, 669.1, ...,   0. ,   1. ,   0. ],\n",
       "       [ 90.6,  43.7, 686.9, ...,   0. ,   1. ,   0. ],\n",
       "       ...,\n",
       "       [ 81.6,  56.7, 665.6, ...,   0. ,   0. ,   0. ],\n",
       "       [ 94.4, 146. , 614.7, ...,   0. ,   0. ,   0. ],\n",
       "       [ 79.5,   3. , 106.7, ...,   1. ,   0. ,   0. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b622936b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d6633",
   "metadata": {},
   "source": [
    "# Artificial Nural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "850c679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model \n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim =28,kernel_initializer='he_uniform',activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer ='he_uniform',activation ='relu'))\n",
    "model.add(Dense(1,kernel_initializer ='he_uniform',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6902dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss =  'binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "275e33e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 143.4765 - accuracy: 0.2543 - val_loss: 111.0384 - val_accuracy: 0.3626\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 101.1518 - accuracy: 0.3324 - val_loss: 69.8499 - val_accuracy: 0.3743\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 59.2261 - accuracy: 0.3410 - val_loss: 30.3217 - val_accuracy: 0.3626\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 18.9645 - accuracy: 0.3584 - val_loss: 6.9539 - val_accuracy: 0.5848\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.9659 - accuracy: 0.7197 - val_loss: 7.9247 - val_accuracy: 0.6784\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.6040 - accuracy: 0.6908 - val_loss: 5.6377 - val_accuracy: 0.4620\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5390 - accuracy: 0.6040 - val_loss: 7.3889 - val_accuracy: 0.5146\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.7707 - accuracy: 0.6879 - val_loss: 7.9479 - val_accuracy: 0.5263\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7028 - accuracy: 0.7081 - val_loss: 7.7081 - val_accuracy: 0.5322\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.6152 - accuracy: 0.7052 - val_loss: 6.5969 - val_accuracy: 0.5497\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.4510 - accuracy: 0.7197 - val_loss: 6.9403 - val_accuracy: 0.5497\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.3518 - accuracy: 0.7139 - val_loss: 6.9534 - val_accuracy: 0.5322\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.2880 - accuracy: 0.7197 - val_loss: 6.9590 - val_accuracy: 0.5088\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.2672 - accuracy: 0.7341 - val_loss: 6.3682 - val_accuracy: 0.5322\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.1272 - accuracy: 0.7399 - val_loss: 6.4125 - val_accuracy: 0.5263\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.1051 - accuracy: 0.7543 - val_loss: 6.4050 - val_accuracy: 0.5205\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0467 - accuracy: 0.7312 - val_loss: 6.2677 - val_accuracy: 0.5263\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.9586 - accuracy: 0.7746 - val_loss: 7.1148 - val_accuracy: 0.4854\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.9541 - accuracy: 0.7630 - val_loss: 5.7032 - val_accuracy: 0.5322\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.9137 - accuracy: 0.7717 - val_loss: 6.0732 - val_accuracy: 0.5205\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7953 - accuracy: 0.7572 - val_loss: 4.8690 - val_accuracy: 0.5731\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8385 - accuracy: 0.7890 - val_loss: 5.6799 - val_accuracy: 0.5322\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8238 - accuracy: 0.7948 - val_loss: 5.8177 - val_accuracy: 0.5380\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7108 - accuracy: 0.7948 - val_loss: 4.7796 - val_accuracy: 0.5614\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.8064 - val_loss: 4.6910 - val_accuracy: 0.5673\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.8266 - val_loss: 4.3139 - val_accuracy: 0.5673\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.8121 - val_loss: 4.0935 - val_accuracy: 0.5906\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.8295 - val_loss: 4.3246 - val_accuracy: 0.5614\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.8382 - val_loss: 4.0684 - val_accuracy: 0.5731\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.8497 - val_loss: 4.4956 - val_accuracy: 0.5673\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.8353 - val_loss: 4.3274 - val_accuracy: 0.5731\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.8468 - val_loss: 3.6938 - val_accuracy: 0.6023\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8613 - val_loss: 3.3049 - val_accuracy: 0.6199\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8699 - val_loss: 3.1660 - val_accuracy: 0.6257\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8613 - val_loss: 2.9025 - val_accuracy: 0.6316\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8642 - val_loss: 3.1520 - val_accuracy: 0.6140\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.8671 - val_loss: 3.1185 - val_accuracy: 0.6140\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8786 - val_loss: 2.7833 - val_accuracy: 0.6433\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8497 - val_loss: 3.0992 - val_accuracy: 0.6199\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8786 - val_loss: 3.3837 - val_accuracy: 0.5906\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2823 - accuracy: 0.8728 - val_loss: 2.5960 - val_accuracy: 0.6667\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9046 - val_loss: 2.2623 - val_accuracy: 0.6842\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9249 - val_loss: 2.3100 - val_accuracy: 0.6784\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1581 - accuracy: 0.9393 - val_loss: 1.6389 - val_accuracy: 0.6959\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9306 - val_loss: 1.7108 - val_accuracy: 0.6901\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.9277 - val_loss: 1.5844 - val_accuracy: 0.6901\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9393 - val_loss: 1.4391 - val_accuracy: 0.7018\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9422 - val_loss: 1.8133 - val_accuracy: 0.7018\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9566 - val_loss: 1.4394 - val_accuracy: 0.7018\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1364 - accuracy: 0.9480 - val_loss: 1.5685 - val_accuracy: 0.6959\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9509 - val_loss: 1.6066 - val_accuracy: 0.6959\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9538 - val_loss: 1.6733 - val_accuracy: 0.7018\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9480 - val_loss: 1.5128 - val_accuracy: 0.7018\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9451 - val_loss: 1.5193 - val_accuracy: 0.6959\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9595 - val_loss: 1.6031 - val_accuracy: 0.7018\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9509 - val_loss: 1.8331 - val_accuracy: 0.6725\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9364 - val_loss: 1.5930 - val_accuracy: 0.6959\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9653 - val_loss: 1.4112 - val_accuracy: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1059 - accuracy: 0.9595 - val_loss: 1.3782 - val_accuracy: 0.7251\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9798 - val_loss: 1.3320 - val_accuracy: 0.7310\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0819 - accuracy: 0.9711 - val_loss: 1.1960 - val_accuracy: 0.7310\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9682 - val_loss: 1.1241 - val_accuracy: 0.7310\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9740 - val_loss: 1.2161 - val_accuracy: 0.7310\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9740 - val_loss: 1.1383 - val_accuracy: 0.7368\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9740 - val_loss: 1.0576 - val_accuracy: 0.7427\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9740 - val_loss: 1.0890 - val_accuracy: 0.7427\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9740 - val_loss: 0.9569 - val_accuracy: 0.7485\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9711 - val_loss: 0.8570 - val_accuracy: 0.7602\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9711 - val_loss: 0.7618 - val_accuracy: 0.8012\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9682 - val_loss: 0.9673 - val_accuracy: 0.7544\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9769 - val_loss: 0.9428 - val_accuracy: 0.7544\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9798 - val_loss: 1.1094 - val_accuracy: 0.7368\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9798 - val_loss: 0.9471 - val_accuracy: 0.7661\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.8912 - val_accuracy: 0.7602\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.8650 - val_accuracy: 0.7602\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9682 - val_loss: 0.7148 - val_accuracy: 0.7778\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9798 - val_loss: 0.7456 - val_accuracy: 0.7836\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9827 - val_loss: 0.7598 - val_accuracy: 0.7778\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9682 - val_loss: 0.7390 - val_accuracy: 0.7836\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9740 - val_loss: 0.8416 - val_accuracy: 0.7778\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9798 - val_loss: 0.9123 - val_accuracy: 0.7661\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9682 - val_loss: 0.8650 - val_accuracy: 0.7661\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9798 - val_loss: 0.8519 - val_accuracy: 0.7778\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9682 - val_loss: 0.7531 - val_accuracy: 0.7778\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.7082 - val_accuracy: 0.7895\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0792 - accuracy: 0.9653 - val_loss: 0.6321 - val_accuracy: 0.8304\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9422 - val_loss: 0.6767 - val_accuracy: 0.7895\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9682 - val_loss: 0.8303 - val_accuracy: 0.7778\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.8071 - val_accuracy: 0.7778\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9740 - val_loss: 0.6532 - val_accuracy: 0.8012\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9769 - val_loss: 0.6719 - val_accuracy: 0.7895\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 0.7125 - val_accuracy: 0.7953\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9711 - val_loss: 0.7594 - val_accuracy: 0.7778\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9855 - val_loss: 0.5576 - val_accuracy: 0.8363\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9711 - val_loss: 0.6536 - val_accuracy: 0.7953\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9827 - val_loss: 0.6336 - val_accuracy: 0.8070\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9855 - val_loss: 0.6142 - val_accuracy: 0.8129\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9769 - val_loss: 0.7664 - val_accuracy: 0.7719\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9884 - val_loss: 0.6168 - val_accuracy: 0.8070\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9769 - val_loss: 0.6897 - val_accuracy: 0.7953\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 0.5531 - val_accuracy: 0.8363\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9884 - val_loss: 0.6064 - val_accuracy: 0.8129\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9827 - val_loss: 0.5185 - val_accuracy: 0.8480\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9769 - val_loss: 0.5484 - val_accuracy: 0.8421\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9798 - val_loss: 0.6452 - val_accuracy: 0.7953\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9913 - val_loss: 0.6960 - val_accuracy: 0.7895\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9913 - val_loss: 0.6148 - val_accuracy: 0.8070\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9827 - val_loss: 0.5187 - val_accuracy: 0.8538\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9913 - val_loss: 0.6412 - val_accuracy: 0.8012\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9827 - val_loss: 0.6432 - val_accuracy: 0.8012\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9855 - val_loss: 0.8964 - val_accuracy: 0.7719\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9827 - val_loss: 0.5865 - val_accuracy: 0.8246\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9827 - val_loss: 0.5922 - val_accuracy: 0.8129\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9798 - val_loss: 0.6018 - val_accuracy: 0.8070\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9913 - val_loss: 0.7813 - val_accuracy: 0.7895\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9942 - val_loss: 0.6574 - val_accuracy: 0.7953\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.5978 - val_accuracy: 0.8187\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9884 - val_loss: 0.5658 - val_accuracy: 0.8421\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9855 - val_loss: 0.8346 - val_accuracy: 0.7778\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.6098 - val_accuracy: 0.8070\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9855 - val_loss: 0.5981 - val_accuracy: 0.8187\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9827 - val_loss: 0.6102 - val_accuracy: 0.8129\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9884 - val_loss: 0.5303 - val_accuracy: 0.8596\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9827 - val_loss: 0.5702 - val_accuracy: 0.8421\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9827 - val_loss: 0.7021 - val_accuracy: 0.8012\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9740 - val_loss: 0.5874 - val_accuracy: 0.8129\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.4727 - val_accuracy: 0.8655\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9855 - val_loss: 0.6880 - val_accuracy: 0.8129\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9884 - val_loss: 0.7228 - val_accuracy: 0.8129\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.7783 - val_accuracy: 0.7895\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9942 - val_loss: 0.5437 - val_accuracy: 0.8538\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9884 - val_loss: 0.4990 - val_accuracy: 0.8655\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9855 - val_loss: 0.5757 - val_accuracy: 0.8070\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9798 - val_loss: 0.4720 - val_accuracy: 0.8830\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9624 - val_loss: 0.4548 - val_accuracy: 0.8421\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9769 - val_loss: 0.5657 - val_accuracy: 0.8363\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9913 - val_loss: 0.5956 - val_accuracy: 0.8129\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9855 - val_loss: 0.5279 - val_accuracy: 0.8596\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.4347 - val_accuracy: 0.8655\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9769 - val_loss: 0.5734 - val_accuracy: 0.8187\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.6106 - val_accuracy: 0.8246\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9913 - val_loss: 0.6954 - val_accuracy: 0.8129\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9884 - val_loss: 0.4523 - val_accuracy: 0.8772\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9884 - val_loss: 0.4325 - val_accuracy: 0.8480\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9855 - val_loss: 0.4768 - val_accuracy: 0.8772\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.4916 - val_accuracy: 0.8713\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.4963 - val_accuracy: 0.8655\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.6924 - val_accuracy: 0.8129\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9913 - val_loss: 0.6061 - val_accuracy: 0.8187\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9913 - val_loss: 0.5363 - val_accuracy: 0.8246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f50dcd2df0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(x,y, validation_split = 0.33, epochs = 150, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5de66b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9400\n",
      "accuracy\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "score = model.evaluate(x,y)\n",
    "print((model.metrics_names[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d33e8e",
   "metadata": {},
   "source": [
    "# Artificial Neural Network Model - Tuning of All Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e06196",
   "metadata": {},
   "source": [
    "# Tuning of Hyperparameter : Batch size, epochs, learning rate, Dropout, Activation, Kernel Initializer, Number of neurons in activation number(nueron1 and nueron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7152a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69c23071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.754024e-15</td>\n",
       "      <td>3.070830e-16</td>\n",
       "      <td>7.387171e-17</td>\n",
       "      <td>-3.865380e-17</td>\n",
       "      <td>2.005703e-16</td>\n",
       "      <td>3.362881e-16</td>\n",
       "      <td>-2.676776e-16</td>\n",
       "      <td>-2.841054e-16</td>\n",
       "      <td>-1.274502e-16</td>\n",
       "      <td>4.874674e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.304582e+01</td>\n",
       "      <td>-1.715608e+00</td>\n",
       "      <td>-2.179108e+00</td>\n",
       "      <td>-1.980578e+00</td>\n",
       "      <td>-2.876943e+00</td>\n",
       "      <td>-1.796637e+00</td>\n",
       "      <td>-2.021098e+00</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-2.020198e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.063453e-02</td>\n",
       "      <td>-6.606652e-01</td>\n",
       "      <td>-4.448281e-01</td>\n",
       "      <td>-5.535954e-01</td>\n",
       "      <td>-5.842379e-01</td>\n",
       "      <td>-6.924563e-01</td>\n",
       "      <td>-7.361236e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-2.020198e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.732292e-01</td>\n",
       "      <td>-4.020255e-02</td>\n",
       "      <td>4.691190e-01</td>\n",
       "      <td>-1.364774e-01</td>\n",
       "      <td>7.082076e-02</td>\n",
       "      <td>-1.403660e-01</td>\n",
       "      <td>-9.833712e-03</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-1.938429e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.089598e-01</td>\n",
       "      <td>4.927389e-01</td>\n",
       "      <td>6.696628e-01</td>\n",
       "      <td>3.904086e-01</td>\n",
       "      <td>6.741643e-01</td>\n",
       "      <td>5.344111e-01</td>\n",
       "      <td>4.929823e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-9.870852e-02</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.007353e+00</td>\n",
       "      <td>2.819865e+00</td>\n",
       "      <td>1.261610e+00</td>\n",
       "      <td>1.033538e+01</td>\n",
       "      <td>2.484195e+00</td>\n",
       "      <td>3.417549e+00</td>\n",
       "      <td>3.007063e+00</td>\n",
       "      <td>2.157228e+01</td>\n",
       "      <td>1.695111e+01</td>\n",
       "      <td>2.254407e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -1.754024e-15  3.070830e-16  7.387171e-17 -3.865380e-17  2.005703e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.304582e+01 -1.715608e+00 -2.179108e+00 -1.980578e+00 -2.876943e+00   \n",
       "25%   -8.063453e-02 -6.606652e-01 -4.448281e-01 -5.535954e-01 -5.842379e-01   \n",
       "50%    1.732292e-01 -4.020255e-02  4.691190e-01 -1.364774e-01  7.082076e-02   \n",
       "75%    4.089598e-01  4.927389e-01  6.696628e-01  3.904086e-01  6.741643e-01   \n",
       "max    1.007353e+00  2.819865e+00  1.261610e+00  1.033538e+01  2.484195e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   3.362881e-16 -2.676776e-16 -2.841054e-16 -1.274502e-16  4.874674e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.796637e+00 -2.021098e+00 -7.326831e-02 -2.020198e-01 -4.435755e-01   \n",
       "25%   -6.924563e-01 -7.361236e-01 -7.326831e-02 -2.020198e-01 -4.435755e-01   \n",
       "50%   -1.403660e-01 -9.833712e-03 -7.326831e-02 -1.938429e-01 -4.435755e-01   \n",
       "75%    5.344111e-01  4.929823e-01 -7.326831e-02 -9.870852e-02 -4.435755e-01   \n",
       "max    3.417549e+00  3.007063e+00  2.157228e+01  1.695111e+01  2.254407e+00   \n",
       "\n",
       "       ...            18            19            20            21  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 22            23            24            25            26  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 27  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardization\n",
    "sc = StandardScaler()\n",
    "sc.fit(x)\n",
    "x_std = sc.transform(x)\n",
    "pd.DataFrame(x_std).describe()1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7674ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def create_model1(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1, input_dim = 28, kernel_initializer = init,activation= activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2, input_dim = neuron1, activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation ='sigmoid'))\n",
    "    \n",
    "    adam = adam_v2.Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss ='binary_crossentropy', optimizer =  adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11761c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar\\AppData\\Local\\Temp/ipykernel_1744/944555759.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model1 = KerasClassifier(build_fn = create_model1, verbose = 0)\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model1 = KerasClassifier(build_fn = create_model1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35795643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid serch parameter\n",
    "batch_size = [10,20]\n",
    "epochs = [10,50]\n",
    "learning_rate = [0.01,0.1]\n",
    "dropout_rate = [0.1,0.2]\n",
    "activation_function = ['softmax','tanh']\n",
    "init = ['uniform','normal']\n",
    "neuron1 = [4,8,]\n",
    "neuron2 = [2,4,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86ee2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dictionary of the grid search parameter\n",
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82ecb0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
      "[CV 1/5; 1/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 1/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.971 total time=   1.3s\n",
      "[CV 2/5; 1/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 1/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.769 total time=   1.2s\n",
      "[CV 3/5; 1/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 1/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.680 total time=   1.4s\n",
      "[CV 4/5; 1/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 1/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.835 total time=   1.2s\n",
      "[CV 5/5; 1/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 1/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.845 total time=   1.2s\n",
      "[CV 1/5; 2/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 2/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 2/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 2/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.769 total time=   1.1s\n",
      "[CV 3/5; 2/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 2/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.718 total time=   1.2s\n",
      "[CV 4/5; 2/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 2/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.816 total time=   1.2s\n",
      "[CV 5/5; 2/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 2/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   1.2s\n",
      "[CV 1/5; 3/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 3/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.990 total time=   1.2s\n",
      "[CV 2/5; 3/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 3/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.779 total time=   1.4s\n",
      "[CV 3/5; 3/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 3/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.699 total time=   1.2s\n",
      "[CV 4/5; 3/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 3/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.825 total time=   1.1s\n",
      "[CV 5/5; 3/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 3/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   1.2s\n",
      "[CV 1/5; 4/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 4/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.962 total time=   1.1s\n",
      "[CV 2/5; 4/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 4/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.779 total time=   1.2s\n",
      "[CV 3/5; 4/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 4/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.718 total time=   1.2s\n",
      "[CV 4/5; 4/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 4/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.777 total time=   1.2s\n",
      "[CV 5/5; 4/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 4/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.874 total time=   1.2s\n",
      "[CV 1/5; 5/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 5/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.885 total time=   1.2s\n",
      "[CV 2/5; 5/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 5/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   1.4s\n",
      "[CV 3/5; 5/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 5/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 5/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 5/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.660 total time=   1.2s\n",
      "[CV 5/5; 5/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 5/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 6/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.933 total time=   1.2s\n",
      "[CV 2/5; 6/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 6/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.673 total time=   1.2s\n",
      "[CV 3/5; 6/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 6/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 6/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 6/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.874 total time=   1.2s\n",
      "[CV 5/5; 6/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 6/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.767 total time=   1.4s\n",
      "[CV 1/5; 7/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 7/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.817 total time=   1.1s\n",
      "[CV 2/5; 7/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 7/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.740 total time=   1.2s\n",
      "[CV 3/5; 7/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 7/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.631 total time=   1.2s\n",
      "[CV 4/5; 7/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 7/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   1.1s\n",
      "[CV 5/5; 7/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 7/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 8/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 8/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.875 total time=   1.2s\n",
      "[CV 2/5; 8/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 8/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 8/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 8/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.485 total time=   1.2s\n",
      "[CV 4/5; 8/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 8/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.718 total time=   1.4s\n",
      "[CV 5/5; 8/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 8/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.709 total time=   1.2s\n",
      "[CV 1/5; 9/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 9/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.962 total time=   1.2s\n",
      "[CV 2/5; 9/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 9/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.760 total time=   1.2s\n",
      "[CV 3/5; 9/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 9/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 9/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 9/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.786 total time=   1.2s\n",
      "[CV 5/5; 9/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 9/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.854 total time=   1.2s\n",
      "[CV 1/5; 10/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 10/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   1.2s\n",
      "[CV 2/5; 10/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 10/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.779 total time=   1.1s\n",
      "[CV 3/5; 10/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 10/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.767 total time=   1.4s\n",
      "[CV 4/5; 10/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 10/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.786 total time=   1.2s\n",
      "[CV 5/5; 10/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 10/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.816 total time=   1.2s\n",
      "[CV 1/5; 11/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.942 total time=   1.2s\n",
      "[CV 2/5; 11/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 11/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.779 total time=   1.2s\n",
      "[CV 3/5; 11/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 11/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.689 total time=   1.2s\n",
      "[CV 4/5; 11/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 11/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.796 total time=   1.2s\n",
      "[CV 5/5; 11/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 11/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.825 total time=   1.2s\n",
      "[CV 1/5; 12/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 12/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.952 total time=   1.2s\n",
      "[CV 2/5; 12/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 12/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.769 total time=   1.4s\n",
      "[CV 3/5; 12/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 12/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.728 total time=   1.2s\n",
      "[CV 4/5; 12/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 12/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.767 total time=   1.2s\n",
      "[CV 5/5; 12/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 12/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.854 total time=   1.1s\n",
      "[CV 1/5; 13/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 13/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.981 total time=   1.2s\n",
      "[CV 2/5; 13/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 13/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.654 total time=   1.2s\n",
      "[CV 3/5; 13/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 13/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 13/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 13/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.796 total time=   1.1s\n",
      "[CV 5/5; 13/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 13/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.728 total time=   1.1s\n",
      "[CV 1/5; 14/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 14/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.990 total time=   1.2s\n",
      "[CV 2/5; 14/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 14/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.798 total time=   1.4s\n",
      "[CV 3/5; 14/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 14/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 14/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 14/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.699 total time=   1.2s\n",
      "[CV 5/5; 14/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 14/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.699 total time=   1.1s\n",
      "[CV 1/5; 15/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 15/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.798 total time=   1.2s\n",
      "[CV 2/5; 15/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 15/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.673 total time=   1.2s\n",
      "[CV 3/5; 15/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 15/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.621 total time=   1.2s\n",
      "[CV 4/5; 15/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 15/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.670 total time=   1.2s\n",
      "[CV 5/5; 15/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 15/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.757 total time=   1.2s\n",
      "[CV 1/5; 16/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 16/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.990 total time=   1.4s\n",
      "[CV 2/5; 16/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 16/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   1.1s\n",
      "[CV 3/5; 16/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 16/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.641 total time=   1.1s\n",
      "[CV 4/5; 16/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 16/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   1.2s\n",
      "[CV 5/5; 16/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 16/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 17/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 17/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 17/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 17/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.904 total time=   3.7s\n",
      "[CV 3/5; 17/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 17/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   3.6s\n",
      "[CV 4/5; 17/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 17/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   3.5s\n",
      "[CV 5/5; 17/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 17/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   3.8s\n",
      "[CV 1/5; 18/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 18/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 18/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 18/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.875 total time=   3.5s\n",
      "[CV 3/5; 18/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 18/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   3.6s\n",
      "[CV 4/5; 18/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 18/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   3.6s\n",
      "[CV 5/5; 18/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 18/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   3.5s\n",
      "[CV 1/5; 19/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 19/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.981 total time=   3.4s\n",
      "[CV 2/5; 19/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 19/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.875 total time=   3.4s\n",
      "[CV 3/5; 19/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 19/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.951 total time=   3.4s\n",
      "[CV 4/5; 19/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 19/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.883 total time=   3.5s\n",
      "[CV 5/5; 19/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 19/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.864 total time=   3.2s\n",
      "[CV 1/5; 20/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 20/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.990 total time=   3.5s\n",
      "[CV 2/5; 20/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 20/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.875 total time=   3.3s\n",
      "[CV 3/5; 20/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 20/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   3.5s\n",
      "[CV 4/5; 20/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 20/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   3.5s\n",
      "[CV 5/5; 20/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 20/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   3.3s\n",
      "[CV 1/5; 21/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 21/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.923 total time=   3.5s\n",
      "[CV 2/5; 21/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 21/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.788 total time=   3.4s\n",
      "[CV 3/5; 21/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 21/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.709 total time=   3.7s\n",
      "[CV 4/5; 21/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 21/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   3.2s\n",
      "[CV 5/5; 21/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 21/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.748 total time=   3.3s\n",
      "[CV 1/5; 22/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 22/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.981 total time=   3.4s\n",
      "[CV 2/5; 22/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 22/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.837 total time=   3.5s\n",
      "[CV 3/5; 22/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 22/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.738 total time=   3.4s\n",
      "[CV 4/5; 22/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 22/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.767 total time=   3.4s\n",
      "[CV 5/5; 22/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 22/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.796 total time=   3.5s\n",
      "[CV 1/5; 23/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 23/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.962 total time=   3.4s\n",
      "[CV 2/5; 23/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 23/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.760 total time=   3.8s\n",
      "[CV 3/5; 23/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 23/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.650 total time=   3.3s\n",
      "[CV 4/5; 23/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 23/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.806 total time=   3.6s\n",
      "[CV 5/5; 23/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 23/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.777 total time=   3.6s\n",
      "[CV 1/5; 24/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 24/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.904 total time=   3.6s\n",
      "[CV 2/5; 24/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 24/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   3.4s\n",
      "[CV 3/5; 24/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 24/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.544 total time=   3.6s\n",
      "[CV 4/5; 24/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 24/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   3.5s\n",
      "[CV 5/5; 24/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 24/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.544 total time=   3.3s\n",
      "[CV 1/5; 25/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 25/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.990 total time=   3.5s\n",
      "[CV 2/5; 25/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 25/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   3.6s\n",
      "[CV 3/5; 25/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 25/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   3.5s\n",
      "[CV 4/5; 25/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 25/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   3.5s\n",
      "[CV 5/5; 25/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 25/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.883 total time=   3.5s\n",
      "[CV 1/5; 26/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 26/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 26/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 26/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.875 total time=   3.3s\n",
      "[CV 3/5; 26/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 26/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.903 total time=   3.6s\n",
      "[CV 4/5; 26/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 26/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.932 total time=   3.6s\n",
      "[CV 5/5; 26/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 26/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.893 total time=   3.6s\n",
      "[CV 1/5; 27/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 27/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 27/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 27/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.894 total time=   3.5s\n",
      "[CV 3/5; 27/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 27/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   3.5s\n",
      "[CV 4/5; 27/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 27/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.903 total time=   3.5s\n",
      "[CV 5/5; 27/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 27/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.893 total time=   3.5s\n",
      "[CV 1/5; 28/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 28/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 28/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 28/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.923 total time=   3.3s\n",
      "[CV 3/5; 28/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 28/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   3.5s\n",
      "[CV 4/5; 28/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 28/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.874 total time=   3.5s\n",
      "[CV 5/5; 28/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 28/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.874 total time=   3.3s\n",
      "[CV 1/5; 29/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 29/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.923 total time=   3.3s\n",
      "[CV 2/5; 29/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 29/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.769 total time=   3.5s\n",
      "[CV 3/5; 29/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 29/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.718 total time=   3.5s\n",
      "[CV 4/5; 29/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 29/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.777 total time=   3.6s\n",
      "[CV 5/5; 29/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 29/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.874 total time=   3.3s\n",
      "[CV 1/5; 30/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 30/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 30/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 30/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.760 total time=   3.5s\n",
      "[CV 3/5; 30/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 30/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.718 total time=   3.5s\n",
      "[CV 4/5; 30/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 30/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.689 total time=   3.7s\n",
      "[CV 5/5; 30/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 30/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.757 total time=   3.5s\n",
      "[CV 1/5; 31/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 31/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.904 total time=   3.7s\n",
      "[CV 2/5; 31/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 31/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   4.2s\n",
      "[CV 3/5; 31/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 31/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.631 total time=   3.6s\n",
      "[CV 4/5; 31/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 31/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.728 total time=   3.7s\n",
      "[CV 5/5; 31/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 31/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.796 total time=   3.7s\n",
      "[CV 1/5; 32/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 32/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.885 total time=   3.4s\n",
      "[CV 2/5; 32/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 32/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   3.6s\n",
      "[CV 3/5; 32/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 32/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.718 total time=   3.6s\n",
      "[CV 4/5; 32/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 32/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   3.7s\n",
      "[CV 5/5; 32/256] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 32/256] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.806 total time=   3.6s\n",
      "[CV 1/5; 33/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 33/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 33/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 33/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 33/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 33/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.524 total time=   1.3s\n",
      "[CV 4/5; 33/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 33/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.767 total time=   1.4s\n",
      "[CV 5/5; 33/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 33/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.806 total time=   1.4s\n",
      "[CV 1/5; 34/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 34/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   1.3s\n",
      "[CV 2/5; 34/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 34/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.750 total time=   1.5s\n",
      "[CV 3/5; 34/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 34/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 34/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 34/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.767 total time=   1.2s\n",
      "[CV 5/5; 34/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 34/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.825 total time=   1.2s\n",
      "[CV 1/5; 35/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 35/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.962 total time=   1.3s\n",
      "[CV 2/5; 35/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 35/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.760 total time=   1.3s\n",
      "[CV 3/5; 35/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 35/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.524 total time=   1.3s\n",
      "[CV 4/5; 35/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 35/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.816 total time=   1.2s\n",
      "[CV 5/5; 35/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 35/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.767 total time=   1.2s\n",
      "[CV 1/5; 36/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 36/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.981 total time=   1.4s\n",
      "[CV 2/5; 36/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 36/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.769 total time=   1.1s\n",
      "[CV 3/5; 36/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 36/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.621 total time=   1.2s\n",
      "[CV 4/5; 36/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 36/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.786 total time=   1.2s\n",
      "[CV 5/5; 36/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 36/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.796 total time=   1.4s\n",
      "[CV 1/5; 37/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 37/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.923 total time=   1.3s\n",
      "[CV 2/5; 37/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 37/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 37/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 37/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 37/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 37/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   1.2s\n",
      "[CV 5/5; 37/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 37/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   1.4s\n",
      "[CV 1/5; 38/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 38/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.798 total time=   1.2s\n",
      "[CV 2/5; 38/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 38/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 38/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 38/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.621 total time=   1.3s\n",
      "[CV 4/5; 38/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 38/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.748 total time=   1.2s\n",
      "[CV 5/5; 38/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 38/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 39/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 39/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.865 total time=   1.5s\n",
      "[CV 2/5; 39/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 39/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.692 total time=   1.3s\n",
      "[CV 3/5; 39/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 39/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 39/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 39/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 39/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 39/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.689 total time=   1.2s\n",
      "[CV 1/5; 40/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 40/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.875 total time=   1.2s\n",
      "[CV 2/5; 40/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 40/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 40/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 40/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   1.3s\n",
      "[CV 4/5; 40/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 40/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   1.1s\n",
      "[CV 5/5; 40/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 40/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.777 total time=   1.3s\n",
      "[CV 1/5; 41/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 41/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 41/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 41/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.769 total time=   1.2s\n",
      "[CV 3/5; 41/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 41/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 41/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 41/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.796 total time=   1.2s\n",
      "[CV 5/5; 41/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 41/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.699 total time=   1.3s\n",
      "[CV 1/5; 42/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 42/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 42/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 42/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.779 total time=   1.3s\n",
      "[CV 3/5; 42/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 42/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.709 total time=   1.2s\n",
      "[CV 4/5; 42/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 42/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.796 total time=   1.2s\n",
      "[CV 5/5; 42/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 42/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.835 total time=   1.2s\n",
      "[CV 1/5; 43/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 43/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.971 total time=   1.2s\n",
      "[CV 2/5; 43/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 43/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.760 total time=   1.2s\n",
      "[CV 3/5; 43/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 43/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 43/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 43/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.786 total time=   1.1s\n",
      "[CV 5/5; 43/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 43/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.816 total time=   1.2s\n",
      "[CV 1/5; 44/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 44/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   1.2s\n",
      "[CV 2/5; 44/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 44/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.760 total time=   1.2s\n",
      "[CV 3/5; 44/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 44/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.670 total time=   1.2s\n",
      "[CV 4/5; 44/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 44/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.777 total time=   1.3s\n",
      "[CV 5/5; 44/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 44/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.796 total time=   1.3s\n",
      "[CV 1/5; 45/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 45/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.952 total time=   1.2s\n",
      "[CV 2/5; 45/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 45/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.740 total time=   1.5s\n",
      "[CV 3/5; 45/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 45/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.3s\n",
      "[CV 4/5; 45/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 45/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.660 total time=   1.4s\n",
      "[CV 5/5; 45/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 45/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.660 total time=   1.4s\n",
      "[CV 1/5; 46/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 46/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.904 total time=   1.3s\n",
      "[CV 2/5; 46/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 46/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 46/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 46/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   1.5s\n",
      "[CV 4/5; 46/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 46/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.718 total time=   1.3s\n",
      "[CV 5/5; 46/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 46/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 47/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 47/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.981 total time=   1.6s\n",
      "[CV 2/5; 47/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 47/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.740 total time=   1.2s\n",
      "[CV 3/5; 47/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 47/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 47/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 47/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   1.3s\n",
      "[CV 5/5; 47/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 47/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.748 total time=   1.6s\n",
      "[CV 1/5; 48/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 48/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 48/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 48/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.740 total time=   1.2s\n",
      "[CV 3/5; 48/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 48/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 48/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 48/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   1.3s\n",
      "[CV 5/5; 48/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 48/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.728 total time=   1.5s\n",
      "[CV 1/5; 49/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 49/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.990 total time=   3.6s\n",
      "[CV 2/5; 49/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 49/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.875 total time=   3.3s\n",
      "[CV 3/5; 49/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 49/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.971 total time=   3.8s\n",
      "[CV 4/5; 49/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 49/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   4.9s\n",
      "[CV 5/5; 49/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 49/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.864 total time=   5.0s\n",
      "[CV 1/5; 50/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 50/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.7s\n",
      "[CV 2/5; 50/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 50/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.865 total time=   3.8s\n",
      "[CV 3/5; 50/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 50/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   3.6s\n",
      "[CV 4/5; 50/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 50/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.903 total time=   3.8s\n",
      "[CV 5/5; 50/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 50/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   3.5s\n",
      "[CV 1/5; 51/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 51/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.990 total time=   3.6s\n",
      "[CV 2/5; 51/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 51/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.875 total time=   3.3s\n",
      "[CV 3/5; 51/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 51/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.883 total time=   3.3s\n",
      "[CV 4/5; 51/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 51/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.854 total time=   3.6s\n",
      "[CV 5/5; 51/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 51/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   3.4s\n",
      "[CV 1/5; 52/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 52/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 52/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 52/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.885 total time=   3.6s\n",
      "[CV 3/5; 52/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 52/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   3.7s\n",
      "[CV 4/5; 52/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 52/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.845 total time=   3.5s\n",
      "[CV 5/5; 52/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 52/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   3.3s\n",
      "[CV 1/5; 53/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 53/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.837 total time=   3.5s\n",
      "[CV 2/5; 53/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 53/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.769 total time=   3.3s\n",
      "[CV 3/5; 53/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 53/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.7s\n",
      "[CV 4/5; 53/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 53/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.738 total time=   3.4s\n",
      "[CV 5/5; 53/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 53/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.786 total time=   3.5s\n",
      "[CV 1/5; 54/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 54/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.962 total time=   3.5s\n",
      "[CV 2/5; 54/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 54/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.769 total time=   3.7s\n",
      "[CV 3/5; 54/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 54/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.670 total time=   3.4s\n",
      "[CV 4/5; 54/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 54/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.777 total time=   3.4s\n",
      "[CV 5/5; 54/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 54/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.738 total time=   3.5s\n",
      "[CV 1/5; 55/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 55/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.875 total time=   3.4s\n",
      "[CV 2/5; 55/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 55/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   3.4s\n",
      "[CV 3/5; 55/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 55/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.650 total time=   3.4s\n",
      "[CV 4/5; 55/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 55/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   3.4s\n",
      "[CV 5/5; 55/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 55/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.718 total time=   3.6s\n",
      "[CV 1/5; 56/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 56/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.913 total time=   3.5s\n",
      "[CV 2/5; 56/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 56/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   3.7s\n",
      "[CV 3/5; 56/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 56/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.680 total time=   3.5s\n",
      "[CV 4/5; 56/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 56/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.718 total time=   3.5s\n",
      "[CV 5/5; 56/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 56/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.777 total time=   3.3s\n",
      "[CV 1/5; 57/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 57/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   3.5s\n",
      "[CV 2/5; 57/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 57/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.875 total time=   4.0s\n",
      "[CV 3/5; 57/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 57/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.816 total time=   3.3s\n",
      "[CV 4/5; 57/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 57/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.922 total time=   3.5s\n",
      "[CV 5/5; 57/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 57/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.893 total time=   3.5s\n",
      "[CV 1/5; 58/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 58/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 58/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 58/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.885 total time=   3.3s\n",
      "[CV 3/5; 58/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 58/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.854 total time=   3.6s\n",
      "[CV 4/5; 58/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 58/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.903 total time=   3.3s\n",
      "[CV 5/5; 58/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 58/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   3.6s\n",
      "[CV 1/5; 59/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 59/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.5s\n",
      "[CV 2/5; 59/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 59/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.885 total time=   3.6s\n",
      "[CV 3/5; 59/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 59/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.922 total time=   3.8s\n",
      "[CV 4/5; 59/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 59/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.864 total time=   4.0s\n",
      "[CV 5/5; 59/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 59/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.932 total time=   3.8s\n",
      "[CV 1/5; 60/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 60/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 60/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 60/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.885 total time=   4.2s\n",
      "[CV 3/5; 60/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 60/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   4.1s\n",
      "[CV 4/5; 60/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 60/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   3.7s\n",
      "[CV 5/5; 60/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 60/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.864 total time=   6.3s\n",
      "[CV 1/5; 61/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 61/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.962 total time=   6.3s\n",
      "[CV 2/5; 61/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 61/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.760 total time=   3.6s\n",
      "[CV 3/5; 61/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 61/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   3.5s\n",
      "[CV 4/5; 61/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 61/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.767 total time=   3.8s\n",
      "[CV 5/5; 61/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 61/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.738 total time=   3.5s\n",
      "[CV 1/5; 62/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 62/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.933 total time=   3.8s\n",
      "[CV 2/5; 62/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 62/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.769 total time=   3.9s\n",
      "[CV 3/5; 62/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 62/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.689 total time=   3.7s\n",
      "[CV 4/5; 62/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 62/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.786 total time=   3.5s\n",
      "[CV 5/5; 62/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 62/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.854 total time=   4.5s\n",
      "[CV 1/5; 63/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 63/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.990 total time=   3.8s\n",
      "[CV 2/5; 63/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 63/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.760 total time=   3.8s\n",
      "[CV 3/5; 63/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 63/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   3.8s\n",
      "[CV 4/5; 63/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 63/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   3.6s\n",
      "[CV 5/5; 63/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 63/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   3.8s\n",
      "[CV 1/5; 64/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 64/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.981 total time=   4.2s\n",
      "[CV 2/5; 64/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 64/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   3.4s\n",
      "[CV 3/5; 64/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 64/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.718 total time=   3.8s\n",
      "[CV 4/5; 64/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 64/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.718 total time=   3.8s\n",
      "[CV 5/5; 64/256] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 64/256] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.709 total time=   3.4s\n",
      "[CV 1/5; 65/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 65/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 65/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 65/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 65/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 65/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 65/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 65/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.689 total time=   0.9s\n",
      "[CV 5/5; 65/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 65/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.738 total time=   0.9s\n",
      "[CV 1/5; 66/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 66/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.904 total time=   1.0s\n",
      "[CV 2/5; 66/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 66/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 66/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 66/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 66/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 66/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.728 total time=   1.0s\n",
      "[CV 5/5; 66/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 66/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.718 total time=   1.3s\n",
      "[CV 1/5; 67/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 67/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 67/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 67/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 67/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 67/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 67/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 67/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.680 total time=   1.1s\n",
      "[CV 5/5; 67/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 67/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.757 total time=   1.2s\n",
      "[CV 1/5; 68/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 68/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.971 total time=   1.1s\n",
      "[CV 2/5; 68/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 68/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.760 total time=   1.1s\n",
      "[CV 3/5; 68/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 68/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.621 total time=   1.6s\n",
      "[CV 4/5; 68/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 68/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.718 total time=   1.0s\n",
      "[CV 5/5; 68/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 68/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.728 total time=   1.7s\n",
      "[CV 1/5; 69/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 69/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.990 total time=   1.0s\n",
      "[CV 2/5; 69/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 69/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.798 total time=   1.2s\n",
      "[CV 3/5; 69/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 69/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 69/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 69/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 69/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 69/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.767 total time=   1.2s\n",
      "[CV 1/5; 70/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 70/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.885 total time=   1.1s\n",
      "[CV 2/5; 70/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 70/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.798 total time=   1.1s\n",
      "[CV 3/5; 70/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 70/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.738 total time=   0.9s\n",
      "[CV 4/5; 70/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 70/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.728 total time=   1.1s\n",
      "[CV 5/5; 70/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 70/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   1.3s\n",
      "[CV 1/5; 71/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 71/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.971 total time=   0.9s\n",
      "[CV 2/5; 71/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 71/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.702 total time=   0.9s\n",
      "[CV 3/5; 71/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 71/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 71/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 71/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.777 total time=   0.9s\n",
      "[CV 5/5; 71/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 71/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.786 total time=   0.9s\n",
      "[CV 1/5; 72/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 72/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.942 total time=   1.0s\n",
      "[CV 2/5; 72/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 72/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   1.2s\n",
      "[CV 3/5; 72/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 72/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.650 total time=   1.0s\n",
      "[CV 4/5; 72/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 72/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.728 total time=   1.3s\n",
      "[CV 5/5; 72/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 72/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.738 total time=   0.9s\n",
      "[CV 1/5; 73/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 73/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 73/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 73/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 73/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 73/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 73/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 73/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.718 total time=   0.9s\n",
      "[CV 5/5; 73/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 73/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 74/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 74/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   0.9s\n",
      "[CV 2/5; 74/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 74/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 74/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 74/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 74/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 74/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.699 total time=   0.9s\n",
      "[CV 5/5; 74/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 74/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.777 total time=   0.9s\n",
      "[CV 1/5; 75/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 75/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.990 total time=   0.9s\n",
      "[CV 2/5; 75/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 75/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 75/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 75/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 75/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 75/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.680 total time=   0.9s\n",
      "[CV 5/5; 75/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 75/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.709 total time=   1.0s\n",
      "[CV 1/5; 76/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 76/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.990 total time=   1.1s\n",
      "[CV 2/5; 76/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 76/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.760 total time=   1.2s\n",
      "[CV 3/5; 76/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 76/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 76/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 76/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.709 total time=   0.9s\n",
      "[CV 5/5; 76/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 76/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.709 total time=   0.9s\n",
      "[CV 1/5; 77/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 77/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.837 total time=   0.9s\n",
      "[CV 2/5; 77/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 77/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.760 total time=   0.9s\n",
      "[CV 3/5; 77/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 77/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.612 total time=   0.9s\n",
      "[CV 4/5; 77/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 77/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.728 total time=   0.9s\n",
      "[CV 5/5; 77/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 77/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.767 total time=   0.9s\n",
      "[CV 1/5; 78/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 78/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.971 total time=   1.1s\n",
      "[CV 2/5; 78/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 78/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.769 total time=   0.9s\n",
      "[CV 3/5; 78/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 78/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.728 total time=   0.9s\n",
      "[CV 4/5; 78/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 78/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.709 total time=   0.9s\n",
      "[CV 5/5; 78/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 78/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.835 total time=   0.9s\n",
      "[CV 1/5; 79/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 79/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.942 total time=   0.9s\n",
      "[CV 2/5; 79/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 79/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 79/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 79/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.748 total time=   0.9s\n",
      "[CV 4/5; 79/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 79/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.728 total time=   1.0s\n",
      "[CV 5/5; 79/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 79/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   1.5s\n",
      "[CV 1/5; 80/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 80/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.846 total time=   0.9s\n",
      "[CV 2/5; 80/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 80/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.760 total time=   1.1s\n",
      "[CV 3/5; 80/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 80/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 80/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 80/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.757 total time=   1.1s\n",
      "[CV 5/5; 80/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 80/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.718 total time=   1.1s\n",
      "[CV 1/5; 81/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 81/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.990 total time=   2.4s\n",
      "[CV 2/5; 81/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 81/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.865 total time=   2.3s\n",
      "[CV 3/5; 81/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 81/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.874 total time=   2.1s\n",
      "[CV 4/5; 81/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 81/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   2.1s\n",
      "[CV 5/5; 81/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 81/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   2.2s\n",
      "[CV 1/5; 82/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 82/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 82/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 82/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.894 total time=   2.1s\n",
      "[CV 3/5; 82/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 82/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.825 total time=   2.0s\n",
      "[CV 4/5; 82/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 82/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.883 total time=   2.1s\n",
      "[CV 5/5; 82/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 82/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.883 total time=   2.1s\n",
      "[CV 1/5; 83/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 83/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.990 total time=   2.3s\n",
      "[CV 2/5; 83/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 83/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.837 total time=   2.4s\n",
      "[CV 3/5; 83/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 83/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.932 total time=   2.1s\n",
      "[CV 4/5; 83/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 83/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.883 total time=   2.2s\n",
      "[CV 5/5; 83/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 83/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.864 total time=   2.1s\n",
      "[CV 1/5; 84/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 84/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.990 total time=   2.1s\n",
      "[CV 2/5; 84/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 84/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.865 total time=   2.0s\n",
      "[CV 3/5; 84/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 84/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.932 total time=   2.1s\n",
      "[CV 4/5; 84/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 84/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.874 total time=   2.1s\n",
      "[CV 5/5; 84/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 84/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   2.0s\n",
      "[CV 1/5; 85/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 85/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 85/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 85/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.788 total time=   2.0s\n",
      "[CV 3/5; 85/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 85/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   2.2s\n",
      "[CV 4/5; 85/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 85/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.864 total time=   2.1s\n",
      "[CV 5/5; 85/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 85/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   2.1s\n",
      "[CV 1/5; 86/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 86/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.990 total time=   2.0s\n",
      "[CV 2/5; 86/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 86/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.779 total time=   2.0s\n",
      "[CV 3/5; 86/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 86/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.767 total time=   2.1s\n",
      "[CV 4/5; 86/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 86/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   2.0s\n",
      "[CV 5/5; 86/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 86/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.816 total time=   2.1s\n",
      "[CV 1/5; 87/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 87/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.981 total time=   2.1s\n",
      "[CV 2/5; 87/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 87/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.779 total time=   2.3s\n",
      "[CV 3/5; 87/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 87/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.845 total time=   2.0s\n",
      "[CV 4/5; 87/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 87/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.777 total time=   2.1s\n",
      "[CV 5/5; 87/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 87/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.825 total time=   2.1s\n",
      "[CV 1/5; 88/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 88/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.990 total time=   2.1s\n",
      "[CV 2/5; 88/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 88/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.817 total time=   2.1s\n",
      "[CV 3/5; 88/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 88/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.641 total time=   2.1s\n",
      "[CV 4/5; 88/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 88/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.845 total time=   2.1s\n",
      "[CV 5/5; 88/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 88/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.845 total time=   2.1s\n",
      "[CV 1/5; 89/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 89/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.2s\n",
      "[CV 2/5; 89/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 89/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.875 total time=   2.1s\n",
      "[CV 3/5; 89/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 89/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   2.0s\n",
      "[CV 4/5; 89/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 89/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.922 total time=   2.0s\n",
      "[CV 5/5; 89/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 89/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.893 total time=   2.1s\n",
      "[CV 1/5; 90/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 90/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 90/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 90/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.875 total time=   2.0s\n",
      "[CV 3/5; 90/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 90/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   2.1s\n",
      "[CV 4/5; 90/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 90/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.932 total time=   2.0s\n",
      "[CV 5/5; 90/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 90/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.883 total time=   2.2s\n",
      "[CV 1/5; 91/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 91/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 91/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 91/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.837 total time=   2.1s\n",
      "[CV 3/5; 91/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 91/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   2.0s\n",
      "[CV 4/5; 91/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 91/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.883 total time=   2.1s\n",
      "[CV 5/5; 91/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 91/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.854 total time=   2.2s\n",
      "[CV 1/5; 92/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 92/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 92/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 92/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.865 total time=   2.3s\n",
      "[CV 3/5; 92/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 92/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   2.1s\n",
      "[CV 4/5; 92/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 92/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.874 total time=   2.3s\n",
      "[CV 5/5; 92/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 92/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.854 total time=   2.1s\n",
      "[CV 1/5; 93/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 93/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.962 total time=   2.1s\n",
      "[CV 2/5; 93/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 93/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.769 total time=   2.1s\n",
      "[CV 3/5; 93/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 93/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.728 total time=   2.2s\n",
      "[CV 4/5; 93/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 93/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   2.2s\n",
      "[CV 5/5; 93/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 93/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.893 total time=   2.1s\n",
      "[CV 1/5; 94/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 94/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 94/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 94/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.817 total time=   2.1s\n",
      "[CV 3/5; 94/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 94/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.670 total time=   2.0s\n",
      "[CV 4/5; 94/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 94/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.864 total time=   2.5s\n",
      "[CV 5/5; 94/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 94/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.864 total time=   2.1s\n",
      "[CV 1/5; 95/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 95/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.942 total time=   2.0s\n",
      "[CV 2/5; 95/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 95/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.760 total time=   2.3s\n",
      "[CV 3/5; 95/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 95/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.806 total time=   2.4s\n",
      "[CV 4/5; 95/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 95/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.777 total time=   2.1s\n",
      "[CV 5/5; 95/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 95/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.767 total time=   2.1s\n",
      "[CV 1/5; 96/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 96/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.837 total time=   2.1s\n",
      "[CV 2/5; 96/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 96/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.827 total time=   2.3s\n",
      "[CV 3/5; 96/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 96/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.757 total time=   2.5s\n",
      "[CV 4/5; 96/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 96/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   2.0s\n",
      "[CV 5/5; 96/256] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 96/256] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.786 total time=   2.2s\n",
      "[CV 1/5; 97/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 97/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 97/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 97/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 97/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 97/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 97/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 97/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.680 total time=   0.9s\n",
      "[CV 5/5; 97/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 97/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 98/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 98/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   0.9s\n",
      "[CV 2/5; 98/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 98/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 98/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 98/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 98/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 98/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 98/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 98/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 99/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 99/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 99/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 99/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 99/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 99/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 99/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 99/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.680 total time=   0.9s\n",
      "[CV 5/5; 99/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 99/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.699 total time=   1.1s\n",
      "[CV 1/5; 100/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 100/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 100/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 100/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 100/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 100/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 100/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 100/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.680 total time=   0.9s\n",
      "[CV 5/5; 100/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 100/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.738 total time=   0.9s\n",
      "[CV 1/5; 101/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 101/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.981 total time=   1.0s\n",
      "[CV 2/5; 101/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 101/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.760 total time=   0.9s\n",
      "[CV 3/5; 101/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 101/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 101/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 101/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.718 total time=   0.9s\n",
      "[CV 5/5; 101/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 101/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.738 total time=   1.1s\n",
      "[CV 1/5; 102/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 102/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 102/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 102/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.712 total time=   0.9s\n",
      "[CV 3/5; 102/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 102/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 102/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 102/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.728 total time=   1.0s\n",
      "[CV 5/5; 102/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 102/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.767 total time=   0.9s\n",
      "[CV 1/5; 103/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 103/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.942 total time=   0.9s\n",
      "[CV 2/5; 103/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 103/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.760 total time=   0.9s\n",
      "[CV 3/5; 103/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 103/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 103/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 103/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.670 total time=   1.0s\n",
      "[CV 5/5; 103/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 103/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.641 total time=   1.1s\n",
      "[CV 1/5; 104/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 104/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.913 total time=   0.9s\n",
      "[CV 2/5; 104/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 104/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 104/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 104/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 104/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 104/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.718 total time=   1.0s\n",
      "[CV 5/5; 104/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 104/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.670 total time=   1.0s\n",
      "[CV 1/5; 105/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 105/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 105/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 105/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 105/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 105/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 105/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 105/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.680 total time=   1.2s\n",
      "[CV 5/5; 105/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 105/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 106/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 106/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 106/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 106/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 106/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 106/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 106/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 106/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.699 total time=   1.0s\n",
      "[CV 5/5; 106/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 106/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 107/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 107/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 107/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 107/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 107/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 107/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 107/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 107/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.699 total time=   1.2s\n",
      "[CV 5/5; 107/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 107/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 108/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 108/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 108/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 108/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 108/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 108/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 108/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 108/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.689 total time=   1.0s\n",
      "[CV 5/5; 108/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 108/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.748 total time=   0.9s\n",
      "[CV 1/5; 109/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 109/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.808 total time=   1.0s\n",
      "[CV 2/5; 109/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 109/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.760 total time=   1.0s\n",
      "[CV 3/5; 109/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 109/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.641 total time=   1.1s\n",
      "[CV 4/5; 109/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 109/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   0.9s\n",
      "[CV 5/5; 109/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 109/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 110/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 110/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.913 total time=   1.1s\n",
      "[CV 2/5; 110/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 110/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.740 total time=   1.0s\n",
      "[CV 3/5; 110/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 110/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.738 total time=   0.9s\n",
      "[CV 4/5; 110/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 110/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.680 total time=   0.9s\n",
      "[CV 5/5; 110/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 110/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.738 total time=   1.0s\n",
      "[CV 1/5; 111/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 111/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 111/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 111/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.779 total time=   1.0s\n",
      "[CV 3/5; 111/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 111/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.718 total time=   1.1s\n",
      "[CV 4/5; 111/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 111/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.650 total time=   0.9s\n",
      "[CV 5/5; 111/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 111/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 112/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 112/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 112/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 112/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.702 total time=   0.9s\n",
      "[CV 3/5; 112/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 112/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 112/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 112/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   0.9s\n",
      "[CV 5/5; 112/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 112/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   0.9s\n",
      "[CV 1/5; 113/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 113/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.4s\n",
      "[CV 2/5; 113/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 113/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.885 total time=   2.7s\n",
      "[CV 3/5; 113/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 113/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.854 total time=   3.0s\n",
      "[CV 4/5; 113/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 113/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   2.6s\n",
      "[CV 5/5; 113/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 113/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.883 total time=   2.1s\n",
      "[CV 1/5; 114/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 114/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 114/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 114/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.846 total time=   2.5s\n",
      "[CV 3/5; 114/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 114/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.893 total time=   2.5s\n",
      "[CV 4/5; 114/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 114/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.922 total time=   2.2s\n",
      "[CV 5/5; 114/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 114/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.922 total time=   2.1s\n",
      "[CV 1/5; 115/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 115/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.990 total time=   2.1s\n",
      "[CV 2/5; 115/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 115/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.875 total time=   2.0s\n",
      "[CV 3/5; 115/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 115/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.864 total time=   2.5s\n",
      "[CV 4/5; 115/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 115/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   2.3s\n",
      "[CV 5/5; 115/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 115/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   2.3s\n",
      "[CV 1/5; 116/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 116/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.990 total time=   2.1s\n",
      "[CV 2/5; 116/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 116/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.846 total time=   2.3s\n",
      "[CV 3/5; 116/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 116/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.835 total time=   2.3s\n",
      "[CV 4/5; 116/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 116/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.864 total time=   2.1s\n",
      "[CV 5/5; 116/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 116/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.864 total time=   2.0s\n",
      "[CV 1/5; 117/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 117/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.913 total time=   2.2s\n",
      "[CV 2/5; 117/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 117/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.837 total time=   2.2s\n",
      "[CV 3/5; 117/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 117/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   2.6s\n",
      "[CV 4/5; 117/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 117/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   2.3s\n",
      "[CV 5/5; 117/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 117/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   2.2s\n",
      "[CV 1/5; 118/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 118/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.990 total time=   2.1s\n",
      "[CV 2/5; 118/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 118/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.865 total time=   2.3s\n",
      "[CV 3/5; 118/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 118/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.748 total time=   2.3s\n",
      "[CV 4/5; 118/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 118/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.835 total time=   2.1s\n",
      "[CV 5/5; 118/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 118/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   2.1s\n",
      "[CV 1/5; 119/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 119/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.962 total time=   2.2s\n",
      "[CV 2/5; 119/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 119/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.760 total time=   2.5s\n",
      "[CV 3/5; 119/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 119/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.631 total time=   2.5s\n",
      "[CV 4/5; 119/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 119/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   2.3s\n",
      "[CV 5/5; 119/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 119/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.689 total time=   2.2s\n",
      "[CV 1/5; 120/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 120/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.913 total time=   2.2s\n",
      "[CV 2/5; 120/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 120/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.760 total time=   2.2s\n",
      "[CV 3/5; 120/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 120/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.718 total time=   2.3s\n",
      "[CV 4/5; 120/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 120/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.777 total time=   2.2s\n",
      "[CV 5/5; 120/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 120/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.786 total time=   2.0s\n",
      "[CV 1/5; 121/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 121/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.981 total time=   2.3s\n",
      "[CV 2/5; 121/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 121/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.885 total time=   2.3s\n",
      "[CV 3/5; 121/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 121/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   2.1s\n",
      "[CV 4/5; 121/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 121/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   2.2s\n",
      "[CV 5/5; 121/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 121/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   2.3s\n",
      "[CV 1/5; 122/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 122/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   2.2s\n",
      "[CV 2/5; 122/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 122/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.856 total time=   2.3s\n",
      "[CV 3/5; 122/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 122/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.932 total time=   2.1s\n",
      "[CV 4/5; 122/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 122/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   2.1s\n",
      "[CV 5/5; 122/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 122/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   2.1s\n",
      "[CV 1/5; 123/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 123/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.981 total time=   2.3s\n",
      "[CV 2/5; 123/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 123/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.865 total time=   2.1s\n",
      "[CV 3/5; 123/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 123/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.883 total time=   2.2s\n",
      "[CV 4/5; 123/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 123/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   2.2s\n",
      "[CV 5/5; 123/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 123/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.864 total time=   2.1s\n",
      "[CV 1/5; 124/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 124/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 124/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 124/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.865 total time=   2.0s\n",
      "[CV 3/5; 124/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 124/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   2.0s\n",
      "[CV 4/5; 124/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 124/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   2.1s\n",
      "[CV 5/5; 124/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 124/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.864 total time=   2.2s\n",
      "[CV 1/5; 125/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 125/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 125/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 125/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.769 total time=   2.1s\n",
      "[CV 3/5; 125/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 125/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.738 total time=   2.0s\n",
      "[CV 4/5; 125/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 125/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.728 total time=   2.0s\n",
      "[CV 5/5; 125/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 125/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.767 total time=   2.4s\n",
      "[CV 1/5; 126/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 126/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 126/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 126/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.808 total time=   2.0s\n",
      "[CV 3/5; 126/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 126/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.680 total time=   2.1s\n",
      "[CV 4/5; 126/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 126/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.786 total time=   2.2s\n",
      "[CV 5/5; 126/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 126/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   2.4s\n",
      "[CV 1/5; 127/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 127/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 127/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 127/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.788 total time=   2.1s\n",
      "[CV 3/5; 127/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 127/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.709 total time=   2.2s\n",
      "[CV 4/5; 127/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 127/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.748 total time=   2.1s\n",
      "[CV 5/5; 127/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 127/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   2.1s\n",
      "[CV 1/5; 128/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 128/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.962 total time=   2.2s\n",
      "[CV 2/5; 128/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 128/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   2.1s\n",
      "[CV 3/5; 128/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 128/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.650 total time=   2.1s\n",
      "[CV 4/5; 128/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 128/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.767 total time=   2.4s\n",
      "[CV 5/5; 128/256] START activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 128/256] END activation_function=softmax, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.796 total time=   2.1s\n",
      "[CV 1/5; 129/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 129/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.942 total time=   1.2s\n",
      "[CV 2/5; 129/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 129/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.817 total time=   1.3s\n",
      "[CV 3/5; 129/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 129/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.825 total time=   1.2s\n",
      "[CV 4/5; 129/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 129/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   1.2s\n",
      "[CV 5/5; 129/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 129/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.864 total time=   1.2s\n",
      "[CV 1/5; 130/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 130/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   1.2s\n",
      "[CV 2/5; 130/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 130/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.837 total time=   1.4s\n",
      "[CV 3/5; 130/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 130/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   1.4s\n",
      "[CV 4/5; 130/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 130/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   1.7s\n",
      "[CV 5/5; 130/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 130/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.893 total time=   1.4s\n",
      "[CV 1/5; 131/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 131/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.990 total time=   1.3s\n",
      "[CV 2/5; 131/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 131/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.846 total time=   1.3s\n",
      "[CV 3/5; 131/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 131/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.825 total time=   1.2s\n",
      "[CV 4/5; 131/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 131/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.883 total time=   1.2s\n",
      "[CV 5/5; 131/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 131/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.893 total time=   1.2s\n",
      "[CV 1/5; 132/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 132/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.990 total time=   1.3s\n",
      "[CV 2/5; 132/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 132/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.865 total time=   1.3s\n",
      "[CV 3/5; 132/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 132/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.864 total time=   1.1s\n",
      "[CV 4/5; 132/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 132/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   1.2s\n",
      "[CV 5/5; 132/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 132/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.922 total time=   1.5s\n",
      "[CV 1/5; 133/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 133/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.885 total time=   1.1s\n",
      "[CV 2/5; 133/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 133/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.702 total time=   1.2s\n",
      "[CV 3/5; 133/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 133/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.718 total time=   1.2s\n",
      "[CV 4/5; 133/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 133/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.777 total time=   1.4s\n",
      "[CV 5/5; 133/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 133/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.777 total time=   1.3s\n",
      "[CV 1/5; 134/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 134/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.981 total time=   1.2s\n",
      "[CV 2/5; 134/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 134/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.788 total time=   1.5s\n",
      "[CV 3/5; 134/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 134/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.670 total time=   1.4s\n",
      "[CV 4/5; 134/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 134/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.777 total time=   1.2s\n",
      "[CV 5/5; 134/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 134/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   1.8s\n",
      "[CV 1/5; 135/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 135/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.837 total time=   1.2s\n",
      "[CV 2/5; 135/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 135/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.760 total time=   1.1s\n",
      "[CV 3/5; 135/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 135/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.748 total time=   1.1s\n",
      "[CV 4/5; 135/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 135/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.728 total time=   1.1s\n",
      "[CV 5/5; 135/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 135/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.718 total time=   1.1s\n",
      "[CV 1/5; 136/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 136/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.846 total time=   1.1s\n",
      "[CV 2/5; 136/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 136/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.779 total time=   1.1s\n",
      "[CV 3/5; 136/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 136/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   1.1s\n",
      "[CV 4/5; 136/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 136/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   1.1s\n",
      "[CV 5/5; 136/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 136/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.806 total time=   1.3s\n",
      "[CV 1/5; 137/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 137/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.990 total time=   1.1s\n",
      "[CV 2/5; 137/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 137/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.827 total time=   1.1s\n",
      "[CV 3/5; 137/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 137/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.874 total time=   1.1s\n",
      "[CV 4/5; 137/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 137/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.893 total time=   1.1s\n",
      "[CV 5/5; 137/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 137/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   1.2s\n",
      "[CV 1/5; 138/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 138/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   1.1s\n",
      "[CV 2/5; 138/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 138/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.856 total time=   1.1s\n",
      "[CV 3/5; 138/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 138/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.903 total time=   1.2s\n",
      "[CV 4/5; 138/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 138/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.903 total time=   1.1s\n",
      "[CV 5/5; 138/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 138/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.893 total time=   1.3s\n",
      "[CV 1/5; 139/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 139/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.923 total time=   1.1s\n",
      "[CV 2/5; 139/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 139/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.827 total time=   1.1s\n",
      "[CV 3/5; 139/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 139/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   1.1s\n",
      "[CV 4/5; 139/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 139/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.903 total time=   1.2s\n",
      "[CV 5/5; 139/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 139/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   1.1s\n",
      "[CV 1/5; 140/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 140/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 140/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 140/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.846 total time=   1.2s\n",
      "[CV 3/5; 140/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 140/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   1.1s\n",
      "[CV 4/5; 140/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 140/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.922 total time=   1.1s\n",
      "[CV 5/5; 140/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 140/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.816 total time=   1.4s\n",
      "[CV 1/5; 141/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 141/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.952 total time=   1.1s\n",
      "[CV 2/5; 141/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 141/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.788 total time=   1.1s\n",
      "[CV 3/5; 141/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 141/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.660 total time=   1.2s\n",
      "[CV 4/5; 141/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 141/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   1.1s\n",
      "[CV 5/5; 141/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 141/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 142/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 142/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.538 total time=   1.1s\n",
      "[CV 2/5; 142/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 142/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.769 total time=   1.2s\n",
      "[CV 3/5; 142/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 142/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.650 total time=   1.1s\n",
      "[CV 4/5; 142/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 142/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.796 total time=   1.1s\n",
      "[CV 5/5; 142/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 142/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.718 total time=   1.4s\n",
      "[CV 1/5; 143/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 143/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.837 total time=   1.2s\n",
      "[CV 2/5; 143/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 143/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.740 total time=   1.1s\n",
      "[CV 3/5; 143/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 143/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   1.1s\n",
      "[CV 4/5; 143/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 143/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.806 total time=   1.2s\n",
      "[CV 5/5; 143/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 143/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.757 total time=   1.1s\n",
      "[CV 1/5; 144/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 144/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.952 total time=   1.1s\n",
      "[CV 2/5; 144/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 144/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.788 total time=   1.1s\n",
      "[CV 3/5; 144/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 144/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.825 total time=   1.1s\n",
      "[CV 4/5; 144/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 144/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.709 total time=   1.2s\n",
      "[CV 5/5; 144/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 144/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   1.4s\n",
      "[CV 1/5; 145/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 145/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 145/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 145/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.894 total time=   3.3s\n",
      "[CV 3/5; 145/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 145/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   3.3s\n",
      "[CV 4/5; 145/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 145/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.942 total time=   3.2s\n",
      "[CV 5/5; 145/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 145/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   3.3s\n",
      "[CV 1/5; 146/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 146/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 146/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 146/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.942 total time=   3.4s\n",
      "[CV 3/5; 146/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 146/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   3.1s\n",
      "[CV 4/5; 146/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 146/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.932 total time=   3.6s\n",
      "[CV 5/5; 146/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 146/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.922 total time=   3.1s\n",
      "[CV 1/5; 147/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 147/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 147/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 147/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.933 total time=   3.3s\n",
      "[CV 3/5; 147/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 147/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   3.4s\n",
      "[CV 4/5; 147/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 147/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.932 total time=   3.1s\n",
      "[CV 5/5; 147/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 147/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.893 total time=   3.3s\n",
      "[CV 1/5; 148/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 148/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 148/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 148/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.894 total time=   3.3s\n",
      "[CV 3/5; 148/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 148/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   3.1s\n",
      "[CV 4/5; 148/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 148/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   3.6s\n",
      "[CV 5/5; 148/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 148/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   3.3s\n",
      "[CV 1/5; 149/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 149/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.933 total time=   3.2s\n",
      "[CV 2/5; 149/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 149/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.769 total time=   3.3s\n",
      "[CV 3/5; 149/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 149/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.718 total time=   3.3s\n",
      "[CV 4/5; 149/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 149/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.874 total time=   3.3s\n",
      "[CV 5/5; 149/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 149/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   3.2s\n",
      "[CV 1/5; 150/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 150/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.885 total time=   3.3s\n",
      "[CV 2/5; 150/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 150/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.779 total time=   3.2s\n",
      "[CV 3/5; 150/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 150/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.845 total time=   3.4s\n",
      "[CV 4/5; 150/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 150/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.738 total time=   3.6s\n",
      "[CV 5/5; 150/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 150/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.845 total time=   3.1s\n",
      "[CV 1/5; 151/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 151/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.913 total time=   4.0s\n",
      "[CV 2/5; 151/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 151/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.808 total time=   3.6s\n",
      "[CV 3/5; 151/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 151/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.835 total time=   3.4s\n",
      "[CV 4/5; 151/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 151/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.718 total time=   3.3s\n",
      "[CV 5/5; 151/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 151/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.631 total time=   3.4s\n",
      "[CV 1/5; 152/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 152/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.942 total time=   3.3s\n",
      "[CV 2/5; 152/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 152/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.779 total time=   3.3s\n",
      "[CV 3/5; 152/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 152/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.777 total time=   3.4s\n",
      "[CV 4/5; 152/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 152/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   3.6s\n",
      "[CV 5/5; 152/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 152/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.864 total time=   3.2s\n",
      "[CV 1/5; 153/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 153/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 153/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 153/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.904 total time=   3.3s\n",
      "[CV 3/5; 153/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 153/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   3.3s\n",
      "[CV 4/5; 153/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 153/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.951 total time=   3.3s\n",
      "[CV 5/5; 153/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 153/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   3.1s\n",
      "[CV 1/5; 154/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 154/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 154/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 154/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.885 total time=   3.3s\n",
      "[CV 3/5; 154/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 154/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.922 total time=   3.3s\n",
      "[CV 4/5; 154/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 154/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.951 total time=   3.6s\n",
      "[CV 5/5; 154/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 154/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.951 total time=   3.3s\n",
      "[CV 1/5; 155/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 155/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 155/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 155/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.952 total time=   3.4s\n",
      "[CV 3/5; 155/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 155/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   3.2s\n",
      "[CV 4/5; 155/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 155/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.942 total time=   3.3s\n",
      "[CV 5/5; 155/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 155/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   3.3s\n",
      "[CV 1/5; 156/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 156/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.981 total time=   3.3s\n",
      "[CV 2/5; 156/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 156/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.885 total time=   3.2s\n",
      "[CV 3/5; 156/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 156/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   3.2s\n",
      "[CV 4/5; 156/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 156/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   3.6s\n",
      "[CV 5/5; 156/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 156/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.922 total time=   3.3s\n",
      "[CV 1/5; 157/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 157/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.990 total time=   3.1s\n",
      "[CV 2/5; 157/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 157/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.837 total time=   3.3s\n",
      "[CV 3/5; 157/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 157/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.854 total time=   3.2s\n",
      "[CV 4/5; 157/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 157/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.777 total time=   3.1s\n",
      "[CV 5/5; 157/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 157/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.845 total time=   3.1s\n",
      "[CV 1/5; 158/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 158/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.894 total time=   3.3s\n",
      "[CV 2/5; 158/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 158/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.827 total time=   3.1s\n",
      "[CV 3/5; 158/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 158/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.757 total time=   3.3s\n",
      "[CV 4/5; 158/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 158/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.835 total time=   3.6s\n",
      "[CV 5/5; 158/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 158/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.903 total time=   3.3s\n",
      "[CV 1/5; 159/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 159/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.942 total time=   3.3s\n",
      "[CV 2/5; 159/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 159/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.788 total time=   3.3s\n",
      "[CV 3/5; 159/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 159/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.728 total time=   3.4s\n",
      "[CV 4/5; 159/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 159/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.767 total time=   3.3s\n",
      "[CV 5/5; 159/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 159/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.835 total time=   3.3s\n",
      "[CV 1/5; 160/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 160/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.971 total time=   3.1s\n",
      "[CV 2/5; 160/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 160/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.760 total time=   3.4s\n",
      "[CV 3/5; 160/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 160/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.689 total time=   3.1s\n",
      "[CV 4/5; 160/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 160/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.845 total time=   3.6s\n",
      "[CV 5/5; 160/256] START activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 160/256] END activation_function=tanh, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.835 total time=   3.3s\n",
      "[CV 1/5; 161/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 161/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.962 total time=   1.1s\n",
      "[CV 2/5; 161/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 161/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.846 total time=   1.1s\n",
      "[CV 3/5; 161/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 161/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.796 total time=   1.1s\n",
      "[CV 4/5; 161/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 161/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   1.1s\n",
      "[CV 5/5; 161/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 161/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.874 total time=   1.2s\n",
      "[CV 1/5; 162/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 162/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 162/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 162/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.846 total time=   1.1s\n",
      "[CV 3/5; 162/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 162/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.854 total time=   1.2s\n",
      "[CV 4/5; 162/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 162/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.893 total time=   1.3s\n",
      "[CV 5/5; 162/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 162/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   1.1s\n",
      "[CV 1/5; 163/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 163/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 163/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 163/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.865 total time=   1.1s\n",
      "[CV 3/5; 163/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 163/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.835 total time=   1.1s\n",
      "[CV 4/5; 163/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 163/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   1.1s\n",
      "[CV 5/5; 163/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 163/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.903 total time=   1.1s\n",
      "[CV 1/5; 164/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 164/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.981 total time=   1.1s\n",
      "[CV 2/5; 164/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 164/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.817 total time=   1.1s\n",
      "[CV 3/5; 164/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 164/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.845 total time=   1.2s\n",
      "[CV 4/5; 164/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 164/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   1.4s\n",
      "[CV 5/5; 164/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 164/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   1.1s\n",
      "[CV 1/5; 165/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 165/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.500 total time=   1.1s\n",
      "[CV 2/5; 165/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 165/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 165/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 165/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.748 total time=   1.1s\n",
      "[CV 4/5; 165/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 165/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.650 total time=   1.1s\n",
      "[CV 5/5; 165/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 165/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.689 total time=   1.1s\n",
      "[CV 1/5; 166/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 166/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.740 total time=   1.1s\n",
      "[CV 2/5; 166/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 166/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 166/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 166/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 166/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 166/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.718 total time=   1.4s\n",
      "[CV 5/5; 166/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 166/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.738 total time=   1.2s\n",
      "[CV 1/5; 167/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 167/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.875 total time=   1.1s\n",
      "[CV 2/5; 167/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 167/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.721 total time=   1.1s\n",
      "[CV 3/5; 167/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 167/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 167/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 167/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.748 total time=   1.1s\n",
      "[CV 5/5; 167/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 167/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.631 total time=   1.1s\n",
      "[CV 1/5; 168/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 168/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.933 total time=   1.1s\n",
      "[CV 2/5; 168/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 168/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.740 total time=   1.1s\n",
      "[CV 3/5; 168/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 168/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.650 total time=   1.1s\n",
      "[CV 4/5; 168/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 168/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.767 total time=   1.3s\n",
      "[CV 5/5; 168/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 168/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.728 total time=   1.1s\n",
      "[CV 1/5; 169/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 169/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.990 total time=   1.1s\n",
      "[CV 2/5; 169/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 169/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.846 total time=   1.1s\n",
      "[CV 3/5; 169/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 169/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.864 total time=   1.2s\n",
      "[CV 4/5; 169/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 169/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.893 total time=   1.1s\n",
      "[CV 5/5; 169/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 169/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.854 total time=   1.1s\n",
      "[CV 1/5; 170/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 170/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   1.1s\n",
      "[CV 2/5; 170/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 170/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.837 total time=   1.1s\n",
      "[CV 3/5; 170/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 170/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.893 total time=   1.1s\n",
      "[CV 4/5; 170/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 170/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.883 total time=   1.4s\n",
      "[CV 5/5; 170/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 170/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   1.1s\n",
      "[CV 1/5; 171/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 171/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 171/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 171/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.865 total time=   1.1s\n",
      "[CV 3/5; 171/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 171/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.825 total time=   1.1s\n",
      "[CV 4/5; 171/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 171/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.883 total time=   1.2s\n",
      "[CV 5/5; 171/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 171/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.883 total time=   1.1s\n",
      "[CV 1/5; 172/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 172/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 172/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 172/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.827 total time=   1.1s\n",
      "[CV 3/5; 172/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 172/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.845 total time=   1.1s\n",
      "[CV 4/5; 172/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 172/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   1.4s\n",
      "[CV 5/5; 172/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 172/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   1.2s\n",
      "[CV 1/5; 173/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 173/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.875 total time=   1.1s\n",
      "[CV 2/5; 173/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 173/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 173/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 173/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 173/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 173/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   1.1s\n",
      "[CV 5/5; 173/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 173/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.660 total time=   1.1s\n",
      "[CV 1/5; 174/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 174/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.990 total time=   1.1s\n",
      "[CV 2/5; 174/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 174/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.712 total time=   1.1s\n",
      "[CV 3/5; 174/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 174/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 174/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 174/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.680 total time=   1.4s\n",
      "[CV 5/5; 174/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 174/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.854 total time=   1.1s\n",
      "[CV 1/5; 175/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 175/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.904 total time=   1.1s\n",
      "[CV 2/5; 175/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 175/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 175/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 175/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 175/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 175/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.718 total time=   1.1s\n",
      "[CV 5/5; 175/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 175/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.767 total time=   1.1s\n",
      "[CV 1/5; 176/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 176/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.913 total time=   1.2s\n",
      "[CV 2/5; 176/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 176/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 176/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 176/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   1.1s\n",
      "[CV 4/5; 176/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 176/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.757 total time=   1.4s\n",
      "[CV 5/5; 176/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 176/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.796 total time=   1.1s\n",
      "[CV 1/5; 177/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 177/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.981 total time=   3.1s\n",
      "[CV 2/5; 177/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 177/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.923 total time=   3.3s\n",
      "[CV 3/5; 177/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 177/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   3.3s\n",
      "[CV 4/5; 177/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 177/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.942 total time=   3.3s\n",
      "[CV 5/5; 177/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 177/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.951 total time=   3.3s\n",
      "[CV 1/5; 178/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 178/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 178/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 178/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.933 total time=   3.3s\n",
      "[CV 3/5; 178/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 178/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.903 total time=   3.1s\n",
      "[CV 4/5; 178/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 178/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.942 total time=   3.6s\n",
      "[CV 5/5; 178/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 178/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.932 total time=   3.3s\n",
      "[CV 1/5; 179/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 179/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 179/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 179/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   3.3s\n",
      "[CV 3/5; 179/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 179/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   3.2s\n",
      "[CV 4/5; 179/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 179/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.932 total time=   3.3s\n",
      "[CV 5/5; 179/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 179/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.922 total time=   3.3s\n",
      "[CV 1/5; 180/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 180/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 180/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 180/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.933 total time=   3.3s\n",
      "[CV 3/5; 180/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 180/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   3.1s\n",
      "[CV 4/5; 180/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 180/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   3.6s\n",
      "[CV 5/5; 180/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 180/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.932 total time=   3.3s\n",
      "[CV 1/5; 181/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 181/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.971 total time=   3.3s\n",
      "[CV 2/5; 181/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 181/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.760 total time=   3.3s\n",
      "[CV 3/5; 181/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 181/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.3s\n",
      "[CV 4/5; 181/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 181/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.806 total time=   3.2s\n",
      "[CV 5/5; 181/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 181/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   3.3s\n",
      "[CV 1/5; 182/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 182/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.990 total time=   3.3s\n",
      "[CV 2/5; 182/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 182/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.798 total time=   3.2s\n",
      "[CV 3/5; 182/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 182/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.748 total time=   3.4s\n",
      "[CV 4/5; 182/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 182/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   3.6s\n",
      "[CV 5/5; 182/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 182/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.864 total time=   3.3s\n",
      "[CV 1/5; 183/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 183/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.923 total time=   3.3s\n",
      "[CV 2/5; 183/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 183/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   3.4s\n",
      "[CV 3/5; 183/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 183/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   3.2s\n",
      "[CV 4/5; 183/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 183/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.748 total time=   3.2s\n",
      "[CV 5/5; 183/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 183/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.631 total time=   3.4s\n",
      "[CV 1/5; 184/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 184/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.990 total time=   3.3s\n",
      "[CV 2/5; 184/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 184/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   3.3s\n",
      "[CV 3/5; 184/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 184/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.728 total time=   3.1s\n",
      "[CV 4/5; 184/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 184/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.767 total time=   3.6s\n",
      "[CV 5/5; 184/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 184/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.806 total time=   3.3s\n",
      "[CV 1/5; 185/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 185/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.990 total time=   3.3s\n",
      "[CV 2/5; 185/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 185/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   3.3s\n",
      "[CV 3/5; 185/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 185/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.922 total time=   3.3s\n",
      "[CV 4/5; 185/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 185/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   3.3s\n",
      "[CV 5/5; 185/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 185/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   3.3s\n",
      "[CV 1/5; 186/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 186/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.981 total time=   3.3s\n",
      "[CV 2/5; 186/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 186/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.885 total time=   3.2s\n",
      "[CV 3/5; 186/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 186/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   3.4s\n",
      "[CV 4/5; 186/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 186/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.932 total time=   3.6s\n",
      "[CV 5/5; 186/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 186/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   3.3s\n",
      "[CV 1/5; 187/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 187/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 187/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 187/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.904 total time=   3.1s\n",
      "[CV 3/5; 187/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 187/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.922 total time=   3.3s\n",
      "[CV 4/5; 187/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 187/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.922 total time=   3.3s\n",
      "[CV 5/5; 187/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 187/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   3.3s\n",
      "[CV 1/5; 188/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 188/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.990 total time=   3.3s\n",
      "[CV 2/5; 188/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 188/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   3.3s\n",
      "[CV 3/5; 188/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 188/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.883 total time=   3.3s\n",
      "[CV 4/5; 188/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 188/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   3.3s\n",
      "[CV 5/5; 188/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 188/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.922 total time=   3.3s\n",
      "[CV 1/5; 189/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 189/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.865 total time=   3.1s\n",
      "[CV 2/5; 189/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 189/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.760 total time=   3.3s\n",
      "[CV 3/5; 189/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 189/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.689 total time=   3.0s\n",
      "[CV 4/5; 189/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 189/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   3.2s\n",
      "[CV 5/5; 189/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 189/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.777 total time=   3.3s\n",
      "[CV 1/5; 190/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 190/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.971 total time=   3.3s\n",
      "[CV 2/5; 190/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 190/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.798 total time=   3.3s\n",
      "[CV 3/5; 190/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 190/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   3.3s\n",
      "[CV 4/5; 190/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 190/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.786 total time=   3.5s\n",
      "[CV 5/5; 190/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 190/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.835 total time=   3.3s\n",
      "[CV 1/5; 191/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 191/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.865 total time=   3.3s\n",
      "[CV 2/5; 191/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 191/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.808 total time=   3.5s\n",
      "[CV 3/5; 191/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 191/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.757 total time=   3.3s\n",
      "[CV 4/5; 191/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 191/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.767 total time=   3.2s\n",
      "[CV 5/5; 191/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 191/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.806 total time=   3.3s\n",
      "[CV 1/5; 192/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 192/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 192/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 192/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   3.3s\n",
      "[CV 3/5; 192/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 192/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.777 total time=   3.3s\n",
      "[CV 4/5; 192/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 192/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.767 total time=   3.4s\n",
      "[CV 5/5; 192/256] START activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 192/256] END activation_function=tanh, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.825 total time=   3.3s\n",
      "[CV 1/5; 193/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 193/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   0.8s\n",
      "[CV 2/5; 193/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 193/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.779 total time=   0.9s\n",
      "[CV 3/5; 193/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 193/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.816 total time=   0.9s\n",
      "[CV 4/5; 193/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 193/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   0.9s\n",
      "[CV 5/5; 193/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 193/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.893 total time=   0.8s\n",
      "[CV 1/5; 194/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 194/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.962 total time=   0.9s\n",
      "[CV 2/5; 194/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 194/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.856 total time=   0.9s\n",
      "[CV 3/5; 194/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 194/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.825 total time=   0.9s\n",
      "[CV 4/5; 194/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 194/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.864 total time=   1.1s\n",
      "[CV 5/5; 194/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 194/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   0.9s\n",
      "[CV 1/5; 195/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 195/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 195/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 195/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.837 total time=   0.8s\n",
      "[CV 3/5; 195/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 195/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.757 total time=   0.9s\n",
      "[CV 4/5; 195/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 195/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.845 total time=   0.8s\n",
      "[CV 5/5; 195/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 195/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.864 total time=   0.9s\n",
      "[CV 1/5; 196/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 196/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 196/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 196/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.827 total time=   0.9s\n",
      "[CV 3/5; 196/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 196/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.816 total time=   0.9s\n",
      "[CV 4/5; 196/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 196/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.864 total time=   1.1s\n",
      "[CV 5/5; 196/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 196/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   0.9s\n",
      "[CV 1/5; 197/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 197/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 197/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 197/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.779 total time=   0.8s\n",
      "[CV 3/5; 197/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 197/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.670 total time=   0.9s\n",
      "[CV 4/5; 197/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 197/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   0.8s\n",
      "[CV 5/5; 197/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 197/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.845 total time=   0.9s\n",
      "[CV 1/5; 198/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 198/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.923 total time=   0.9s\n",
      "[CV 2/5; 198/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 198/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.808 total time=   0.9s\n",
      "[CV 3/5; 198/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 198/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.709 total time=   0.9s\n",
      "[CV 4/5; 198/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 198/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.845 total time=   1.1s\n",
      "[CV 5/5; 198/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 198/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.786 total time=   0.9s\n",
      "[CV 1/5; 199/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 199/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.962 total time=   0.9s\n",
      "[CV 2/5; 199/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 199/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.731 total time=   0.8s\n",
      "[CV 3/5; 199/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 199/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 199/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 199/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.689 total time=   0.9s\n",
      "[CV 5/5; 199/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 199/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.825 total time=   0.9s\n",
      "[CV 1/5; 200/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 200/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.952 total time=   0.9s\n",
      "[CV 2/5; 200/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 200/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.788 total time=   0.9s\n",
      "[CV 3/5; 200/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 200/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.786 total time=   0.8s\n",
      "[CV 4/5; 200/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 200/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   1.1s\n",
      "[CV 5/5; 200/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 200/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.845 total time=   0.9s\n",
      "[CV 1/5; 201/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 201/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.990 total time=   0.9s\n",
      "[CV 2/5; 201/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 201/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.808 total time=   0.8s\n",
      "[CV 3/5; 201/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 201/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.874 total time=   0.8s\n",
      "[CV 4/5; 201/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 201/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.864 total time=   0.9s\n",
      "[CV 5/5; 201/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 201/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.874 total time=   0.9s\n",
      "[CV 1/5; 202/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 202/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 202/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 202/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.846 total time=   0.8s\n",
      "[CV 3/5; 202/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 202/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.835 total time=   0.9s\n",
      "[CV 4/5; 202/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 202/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   1.1s\n",
      "[CV 5/5; 202/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 202/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.883 total time=   0.9s\n",
      "[CV 1/5; 203/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 203/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.875 total time=   0.9s\n",
      "[CV 2/5; 203/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 203/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.856 total time=   0.8s\n",
      "[CV 3/5; 203/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 203/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.845 total time=   0.9s\n",
      "[CV 4/5; 203/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 203/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   0.8s\n",
      "[CV 5/5; 203/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 203/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   0.9s\n",
      "[CV 1/5; 204/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 204/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.971 total time=   0.9s\n",
      "[CV 2/5; 204/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 204/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.846 total time=   0.8s\n",
      "[CV 3/5; 204/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 204/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.854 total time=   0.9s\n",
      "[CV 4/5; 204/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 204/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.874 total time=   1.1s\n",
      "[CV 5/5; 204/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 204/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.893 total time=   0.9s\n",
      "[CV 1/5; 205/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 205/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.923 total time=   0.9s\n",
      "[CV 2/5; 205/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 205/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.760 total time=   0.9s\n",
      "[CV 3/5; 205/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 205/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 205/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 205/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.738 total time=   0.9s\n",
      "[CV 5/5; 205/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 205/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.728 total time=   0.9s\n",
      "[CV 1/5; 206/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 206/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.913 total time=   0.9s\n",
      "[CV 2/5; 206/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 206/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.740 total time=   0.9s\n",
      "[CV 3/5; 206/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 206/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.816 total time=   0.9s\n",
      "[CV 4/5; 206/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 206/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.757 total time=   1.1s\n",
      "[CV 5/5; 206/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 206/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.845 total time=   0.8s\n",
      "[CV 1/5; 207/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 207/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.923 total time=   0.9s\n",
      "[CV 2/5; 207/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 207/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.769 total time=   0.8s\n",
      "[CV 3/5; 207/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 207/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.718 total time=   0.8s\n",
      "[CV 4/5; 207/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 207/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   0.9s\n",
      "[CV 5/5; 207/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 207/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.835 total time=   0.9s\n",
      "[CV 1/5; 208/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 208/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.885 total time=   0.9s\n",
      "[CV 2/5; 208/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 208/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   0.8s\n",
      "[CV 3/5; 208/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 208/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.660 total time=   0.8s\n",
      "[CV 4/5; 208/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 208/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.689 total time=   1.1s\n",
      "[CV 5/5; 208/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 208/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.777 total time=   0.9s\n",
      "[CV 1/5; 209/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 209/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 209/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 209/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.942 total time=   2.0s\n",
      "[CV 3/5; 209/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 209/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   2.0s\n",
      "[CV 4/5; 209/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 209/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.951 total time=   1.9s\n",
      "[CV 5/5; 209/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 209/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.903 total time=   2.0s\n",
      "[CV 1/5; 210/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 210/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 210/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 210/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   2.0s\n",
      "[CV 3/5; 210/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 210/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   2.2s\n",
      "[CV 4/5; 210/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 210/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.951 total time=   2.0s\n",
      "[CV 5/5; 210/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 210/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.961 total time=   2.0s\n",
      "[CV 1/5; 211/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 211/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 211/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 211/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.894 total time=   2.0s\n",
      "[CV 3/5; 211/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 211/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.893 total time=   2.0s\n",
      "[CV 4/5; 211/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 211/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.913 total time=   2.0s\n",
      "[CV 5/5; 211/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 211/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.893 total time=   1.9s\n",
      "[CV 1/5; 212/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 212/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 212/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 212/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.904 total time=   2.0s\n",
      "[CV 3/5; 212/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 212/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.893 total time=   2.2s\n",
      "[CV 4/5; 212/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 212/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.951 total time=   2.0s\n",
      "[CV 5/5; 212/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 212/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   2.0s\n",
      "[CV 1/5; 213/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 213/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 213/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 213/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.846 total time=   2.0s\n",
      "[CV 3/5; 213/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 213/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   2.0s\n",
      "[CV 4/5; 213/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 213/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.796 total time=   2.0s\n",
      "[CV 5/5; 213/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 213/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.845 total time=   2.0s\n",
      "[CV 1/5; 214/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 214/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.981 total time=   1.9s\n",
      "[CV 2/5; 214/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 214/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.817 total time=   2.0s\n",
      "[CV 3/5; 214/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 214/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.796 total time=   2.2s\n",
      "[CV 4/5; 214/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 214/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.864 total time=   2.0s\n",
      "[CV 5/5; 214/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 214/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.893 total time=   2.0s\n",
      "[CV 1/5; 215/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 215/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.990 total time=   2.0s\n",
      "[CV 2/5; 215/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 215/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.769 total time=   2.0s\n",
      "[CV 3/5; 215/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 215/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.835 total time=   2.0s\n",
      "[CV 4/5; 215/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 215/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.806 total time=   2.0s\n",
      "[CV 5/5; 215/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 215/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.854 total time=   2.0s\n",
      "[CV 1/5; 216/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 216/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.990 total time=   2.0s\n",
      "[CV 2/5; 216/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 216/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.798 total time=   2.0s\n",
      "[CV 3/5; 216/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 216/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.806 total time=   2.3s\n",
      "[CV 4/5; 216/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 216/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.864 total time=   1.9s\n",
      "[CV 5/5; 216/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 216/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.893 total time=   2.0s\n",
      "[CV 1/5; 217/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 217/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 217/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 217/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.904 total time=   2.0s\n",
      "[CV 3/5; 217/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 217/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.922 total time=   2.0s\n",
      "[CV 4/5; 217/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 217/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.951 total time=   2.0s\n",
      "[CV 5/5; 217/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 217/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.951 total time=   1.9s\n",
      "[CV 1/5; 218/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 218/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 218/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 218/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.885 total time=   2.0s\n",
      "[CV 3/5; 218/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 218/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   2.2s\n",
      "[CV 4/5; 218/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 218/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.951 total time=   2.0s\n",
      "[CV 5/5; 218/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 218/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.951 total time=   2.0s\n",
      "[CV 1/5; 219/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 219/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 219/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 219/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.933 total time=   2.0s\n",
      "[CV 3/5; 219/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 219/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.903 total time=   2.0s\n",
      "[CV 4/5; 219/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 219/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.951 total time=   2.0s\n",
      "[CV 5/5; 219/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 219/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.922 total time=   2.0s\n",
      "[CV 1/5; 220/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 220/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 220/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 220/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   2.0s\n",
      "[CV 3/5; 220/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 220/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   2.0s\n",
      "[CV 4/5; 220/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 220/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   2.2s\n",
      "[CV 5/5; 220/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 220/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.922 total time=   2.0s\n",
      "[CV 1/5; 221/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 221/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.942 total time=   2.0s\n",
      "[CV 2/5; 221/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 221/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.846 total time=   2.0s\n",
      "[CV 3/5; 221/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 221/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   2.0s\n",
      "[CV 4/5; 221/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 221/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.922 total time=   2.0s\n",
      "[CV 5/5; 221/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 221/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.883 total time=   2.0s\n",
      "[CV 1/5; 222/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 222/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 222/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 222/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.837 total time=   2.0s\n",
      "[CV 3/5; 222/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 222/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.932 total time=   2.0s\n",
      "[CV 4/5; 222/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 222/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.883 total time=   2.2s\n",
      "[CV 5/5; 222/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 222/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.883 total time=   2.0s\n",
      "[CV 1/5; 223/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 223/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.952 total time=   2.0s\n",
      "[CV 2/5; 223/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 223/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.817 total time=   2.0s\n",
      "[CV 3/5; 223/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 223/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.796 total time=   2.0s\n",
      "[CV 4/5; 223/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 223/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.874 total time=   2.0s\n",
      "[CV 5/5; 223/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 223/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.845 total time=   1.9s\n",
      "[CV 1/5; 224/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 224/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.990 total time=   2.0s\n",
      "[CV 2/5; 224/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 224/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.837 total time=   1.9s\n",
      "[CV 3/5; 224/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 224/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.835 total time=   2.0s\n",
      "[CV 4/5; 224/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 224/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.854 total time=   2.2s\n",
      "[CV 5/5; 224/256] START activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 224/256] END activation_function=tanh, batch_size=20, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.864 total time=   2.0s\n",
      "[CV 1/5; 225/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 225/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 225/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 225/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.788 total time=   0.9s\n",
      "[CV 3/5; 225/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 225/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.825 total time=   0.9s\n",
      "[CV 4/5; 225/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 225/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.874 total time=   0.8s\n",
      "[CV 5/5; 225/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 225/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.874 total time=   0.9s\n",
      "[CV 1/5; 226/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 226/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   0.9s\n",
      "[CV 2/5; 226/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 226/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.837 total time=   0.8s\n",
      "[CV 3/5; 226/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 226/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.835 total time=   0.9s\n",
      "[CV 4/5; 226/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 226/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.864 total time=   1.1s\n",
      "[CV 5/5; 226/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 226/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.874 total time=   0.9s\n",
      "[CV 1/5; 227/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 227/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.981 total time=   0.9s\n",
      "[CV 2/5; 227/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 227/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.827 total time=   0.8s\n",
      "[CV 3/5; 227/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 227/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.835 total time=   0.9s\n",
      "[CV 4/5; 227/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 227/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   0.9s\n",
      "[CV 5/5; 227/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 227/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.874 total time=   0.8s\n",
      "[CV 1/5; 228/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 228/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 228/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 228/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.817 total time=   0.9s\n",
      "[CV 3/5; 228/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 228/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.864 total time=   0.9s\n",
      "[CV 4/5; 228/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 228/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.845 total time=   1.1s\n",
      "[CV 5/5; 228/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 228/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.854 total time=   0.9s\n",
      "[CV 1/5; 229/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 229/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.942 total time=   0.8s\n",
      "[CV 2/5; 229/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 229/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.760 total time=   0.9s\n",
      "[CV 3/5; 229/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 229/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.709 total time=   0.9s\n",
      "[CV 4/5; 229/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 229/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   0.9s\n",
      "[CV 5/5; 229/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 229/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.796 total time=   0.9s\n",
      "[CV 1/5; 230/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 230/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.856 total time=   0.8s\n",
      "[CV 2/5; 230/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 230/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 230/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 230/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.631 total time=   0.8s\n",
      "[CV 4/5; 230/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 230/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.689 total time=   1.1s\n",
      "[CV 5/5; 230/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 230/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   0.9s\n",
      "[CV 1/5; 231/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 231/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.952 total time=   0.9s\n",
      "[CV 2/5; 231/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 231/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.740 total time=   0.9s\n",
      "[CV 3/5; 231/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 231/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 231/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 231/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.786 total time=   0.9s\n",
      "[CV 5/5; 231/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 231/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.786 total time=   0.8s\n",
      "[CV 1/5; 232/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 232/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.952 total time=   0.9s\n",
      "[CV 2/5; 232/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 232/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.740 total time=   0.8s\n",
      "[CV 3/5; 232/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 232/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   0.9s\n",
      "[CV 4/5; 232/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 232/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.767 total time=   1.1s\n",
      "[CV 5/5; 232/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 232/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.816 total time=   0.9s\n",
      "[CV 1/5; 233/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 233/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.904 total time=   0.8s\n",
      "[CV 2/5; 233/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 233/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.817 total time=   0.9s\n",
      "[CV 3/5; 233/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 233/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.816 total time=   0.9s\n",
      "[CV 4/5; 233/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 233/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.874 total time=   0.8s\n",
      "[CV 5/5; 233/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 233/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.854 total time=   0.8s\n",
      "[CV 1/5; 234/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 234/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   0.9s\n",
      "[CV 2/5; 234/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 234/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.769 total time=   0.9s\n",
      "[CV 3/5; 234/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 234/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.825 total time=   0.8s\n",
      "[CV 4/5; 234/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 234/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.864 total time=   1.1s\n",
      "[CV 5/5; 234/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 234/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.893 total time=   0.9s\n",
      "[CV 1/5; 235/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 235/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 235/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 235/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.827 total time=   0.9s\n",
      "[CV 3/5; 235/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 235/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.835 total time=   1.3s\n",
      "[CV 4/5; 235/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 235/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.854 total time=   1.0s\n",
      "[CV 5/5; 235/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 235/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.893 total time=   0.9s\n",
      "[CV 1/5; 236/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 236/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.952 total time=   0.9s\n",
      "[CV 2/5; 236/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 236/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.837 total time=   0.9s\n",
      "[CV 3/5; 236/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 236/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.854 total time=   0.9s\n",
      "[CV 4/5; 236/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 236/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.874 total time=   1.1s\n",
      "[CV 5/5; 236/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 236/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.893 total time=   0.9s\n",
      "[CV 1/5; 237/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 237/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.942 total time=   0.8s\n",
      "[CV 2/5; 237/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 237/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.769 total time=   0.8s\n",
      "[CV 3/5; 237/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 237/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   0.9s\n",
      "[CV 4/5; 237/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 237/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.738 total time=   0.8s\n",
      "[CV 5/5; 237/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 237/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   0.9s\n",
      "[CV 1/5; 238/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 238/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.952 total time=   0.8s\n",
      "[CV 2/5; 238/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 238/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.740 total time=   0.9s\n",
      "[CV 3/5; 238/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 238/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.670 total time=   0.8s\n",
      "[CV 4/5; 238/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 238/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.689 total time=   1.1s\n",
      "[CV 5/5; 238/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 238/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.845 total time=   0.9s\n",
      "[CV 1/5; 239/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 239/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.904 total time=   0.8s\n",
      "[CV 2/5; 239/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 239/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 239/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 239/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 239/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 239/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.738 total time=   0.9s\n",
      "[CV 5/5; 239/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 239/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.709 total time=   0.9s\n",
      "[CV 1/5; 240/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 240/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.865 total time=   0.9s\n",
      "[CV 2/5; 240/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 240/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.760 total time=   0.9s\n",
      "[CV 3/5; 240/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 240/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.786 total time=   0.8s\n",
      "[CV 4/5; 240/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 240/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.796 total time=   1.1s\n",
      "[CV 5/5; 240/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 240/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.767 total time=   0.9s\n",
      "[CV 1/5; 241/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 241/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 241/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 241/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   2.0s\n",
      "[CV 3/5; 241/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 241/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.893 total time=   1.9s\n",
      "[CV 4/5; 241/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 241/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.922 total time=   2.0s\n",
      "[CV 5/5; 241/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 241/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.922 total time=   2.0s\n",
      "[CV 1/5; 242/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 242/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   2.0s\n",
      "[CV 2/5; 242/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 242/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.933 total time=   2.0s\n",
      "[CV 3/5; 242/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 242/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.893 total time=   2.0s\n",
      "[CV 4/5; 242/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 242/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.922 total time=   2.2s\n",
      "[CV 5/5; 242/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 242/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.961 total time=   1.9s\n",
      "[CV 1/5; 243/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 243/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 243/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 243/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.894 total time=   2.0s\n",
      "[CV 3/5; 243/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 243/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.922 total time=   1.9s\n",
      "[CV 4/5; 243/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 243/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.942 total time=   2.0s\n",
      "[CV 5/5; 243/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 243/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.942 total time=   2.0s\n",
      "[CV 1/5; 244/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 244/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 244/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 244/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.923 total time=   2.0s\n",
      "[CV 3/5; 244/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 244/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   2.0s\n",
      "[CV 4/5; 244/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 244/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   2.0s\n",
      "[CV 5/5; 244/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 244/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   2.3s\n",
      "[CV 1/5; 245/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 245/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.923 total time=   2.0s\n",
      "[CV 2/5; 245/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 245/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.817 total time=   2.0s\n",
      "[CV 3/5; 245/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 245/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.835 total time=   2.0s\n",
      "[CV 4/5; 245/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 245/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.874 total time=   1.9s\n",
      "[CV 5/5; 245/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 245/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.874 total time=   2.0s\n",
      "[CV 1/5; 246/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 246/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 246/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 246/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.865 total time=   2.0s\n",
      "[CV 3/5; 246/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 246/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.816 total time=   1.9s\n",
      "[CV 4/5; 246/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 246/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.874 total time=   2.0s\n",
      "[CV 5/5; 246/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 246/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   1.9s\n",
      "[CV 1/5; 247/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 247/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.856 total time=   2.2s\n",
      "[CV 2/5; 247/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 247/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.788 total time=   1.9s\n",
      "[CV 3/5; 247/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 247/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.825 total time=   2.0s\n",
      "[CV 4/5; 247/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 247/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.825 total time=   2.0s\n",
      "[CV 5/5; 247/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 247/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.864 total time=   2.0s\n",
      "[CV 1/5; 248/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 248/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.952 total time=   1.9s\n",
      "[CV 2/5; 248/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 248/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.827 total time=   2.0s\n",
      "[CV 3/5; 248/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 248/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.874 total time=   2.0s\n",
      "[CV 4/5; 248/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 248/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.835 total time=   2.0s\n",
      "[CV 5/5; 248/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 248/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.854 total time=   2.0s\n",
      "[CV 1/5; 249/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 249/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.3s\n",
      "[CV 2/5; 249/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 249/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   2.0s\n",
      "[CV 3/5; 249/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 249/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.893 total time=   2.0s\n",
      "[CV 4/5; 249/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 249/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.913 total time=   2.0s\n",
      "[CV 5/5; 249/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 249/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   2.0s\n",
      "[CV 1/5; 250/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 250/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.990 total time=   2.0s\n",
      "[CV 2/5; 250/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 250/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.952 total time=   2.0s\n",
      "[CV 3/5; 250/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 250/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.913 total time=   2.0s\n",
      "[CV 4/5; 250/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 250/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.922 total time=   1.9s\n",
      "[CV 5/5; 250/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 250/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.971 total time=   2.0s\n",
      "[CV 1/5; 251/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 251/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   2.2s\n",
      "[CV 2/5; 251/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 251/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.885 total time=   2.0s\n",
      "[CV 3/5; 251/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 251/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.903 total time=   1.9s\n",
      "[CV 4/5; 251/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 251/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.951 total time=   2.0s\n",
      "[CV 5/5; 251/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 251/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.942 total time=   2.0s\n",
      "[CV 1/5; 252/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 252/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 252/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 252/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.913 total time=   2.0s\n",
      "[CV 3/5; 252/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 252/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.922 total time=   1.9s\n",
      "[CV 4/5; 252/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 252/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.932 total time=   2.0s\n",
      "[CV 5/5; 252/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 252/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.942 total time=   2.0s\n",
      "[CV 1/5; 253/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 253/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.904 total time=   2.2s\n",
      "[CV 2/5; 253/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 253/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.808 total time=   2.0s\n",
      "[CV 3/5; 253/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 253/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.864 total time=   1.9s\n",
      "[CV 4/5; 253/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 253/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.874 total time=   1.9s\n",
      "[CV 5/5; 253/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 253/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.854 total time=   2.0s\n",
      "[CV 1/5; 254/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 254/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 254/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 254/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.846 total time=   2.0s\n",
      "[CV 3/5; 254/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 254/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.845 total time=   2.0s\n",
      "[CV 4/5; 254/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 254/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   2.0s\n",
      "[CV 5/5; 254/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 254/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.893 total time=   2.0s\n",
      "[CV 1/5; 255/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 255/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.923 total time=   2.2s\n",
      "[CV 2/5; 255/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 255/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.760 total time=   2.0s\n",
      "[CV 3/5; 255/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 255/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.825 total time=   1.9s\n",
      "[CV 4/5; 255/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 255/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.845 total time=   2.0s\n",
      "[CV 5/5; 255/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 255/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.854 total time=   1.9s\n",
      "[CV 1/5; 256/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 256/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 256/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 256/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.808 total time=   2.0s\n",
      "[CV 3/5; 256/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 256/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.806 total time=   2.0s\n",
      "[CV 4/5; 256/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 256/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.835 total time=   2.0s\n",
      "[CV 5/5; 256/256] START activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 256/256] END activation_function=tanh, batch_size=20, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.864 total time=   2.0s\n"
     ]
    }
   ],
   "source": [
    "## Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model1, param_grid = param_grids, cv = KFold(), verbose = 10)\n",
    "grid_result = grid.fit(x_std,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ddbb111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9496265888214112, using {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8199215888977051,0.09588069638068977 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8353995561599732,0.09697194771058361 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8334578037261963,0.09733797934370714 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.821863317489624,0.08577931062943986 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7036221027374268,0.11745898464641774 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7541635513305665,0.14544545106349832 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7134802103042602,0.06269241763653717 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7075242698192596,0.12593322357951625 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7772404670715332,0.1444315386333535 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8276325702667237,0.08293575248733416 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8063666939735412,0.08172949083895266 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8141336798667907,0.0802942574680776 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7366318106651306,0.15176533020629263 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7421583414077759,0.15227472701369987 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7039395093917846,0.06424596011722798 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7596900820732116,0.1223199861779339 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9302837967872619,0.03639648645785933 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9148058295249939,0.04590139176376466 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9109596729278564,0.04638678366554905 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9070575118064881,0.04265827898377029 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.77337566614151,0.08125181846107497 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8236557126045227,0.08506491352557367 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7908326983451843,0.1002365762508769 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.6880507826805115,0.13579862853002858 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9264003157615661,0.035563773571885775 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9206310629844665,0.043767464242193944 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9205937266349793,0.04031562008880405 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9147124648094177,0.04654686141774242 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8122479438781738,0.07481034266361916 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7849327802658081,0.1106540665670824 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7618371844291687,0.08912553295790433 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7715832710266113,0.06708533135693863 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7694174766540527,0.15163979340077074 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7713778972625732,0.149935343084962 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7655899882316589,0.14082776728317098 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7907767057418823,0.11429021293720744 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7151979088783265,0.12837869458394063 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7232076287269592,0.059790638101991894 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.6901792407035827,0.10801771853043603 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.725,0.11555437190656304 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7577296614646911,0.15378494496322181 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8237303972244263,0.09715687596324793 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7713965654373169,0.14372602244528074 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7889283061027527,0.08803721844366134 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7073935747146607,0.14062163620947668 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7191187500953674,0.12120001807549152 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.734522032737732,0.1470120155804336 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7480769276618957,0.15100347354306795 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9225914955139161,0.050428777429850045 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9109410047531128,0.047863621341699865 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9031740188598633,0.04745084840898157 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9089619159698487,0.05111825685323386 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7308625817298889,0.10812356406189301 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7830470442771912,0.0968849380378067 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7347087383270263,0.0778577817558876 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7676437616348266,0.0797823899438717 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9012135863304138,0.06049291209153616 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9109036564826966,0.048769285438663 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9206123948097229,0.04675011355855957 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9147871494293213,0.049898032682719154 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7850074648857117,0.09137541256767957 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8064040303230285,0.08214576822928467 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15132599808114525 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7791262149810791,0.10303045189689349 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7402912616729737,0.15284711174055032 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7249439835548401,0.12079372712162156 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7422330021858216,0.1537264536395633 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7597460746765137,0.11536707288105696 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7518670678138732,0.15249598630398897 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7909073829650879,0.05622551778865216 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.752091109752655,0.1443538133638256 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7656086683273315,0.09660387291877569 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7383495211601258,0.1525569895928302 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7480769276618957,0.14968657096258997 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7306011915206909,0.15067414752171268 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7383495092391967,0.1493699363629815 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.74058997631073,0.0735459951527936 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8024458527565003,0.09478662276158532 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7734130024909973,0.08639736259115112 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7211538434028626,0.10693862916230419 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9070761799812317,0.04432011850697037 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8972927570343018,0.05679808488203575 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.90130695104599,0.054364552152860325 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9090179324150085,0.04679111336403678 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8567214488983155,0.07567705290193719 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8315160632133484,0.08135399595895822 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8412434577941894,0.07455809405401331 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.827557897567749,0.11143591067858569 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9245145559310913,0.042875378411704704 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9206310749053955,0.04462060164412092 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8974047780036927,0.05745885254584852 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8954070210456848,0.05316860793643607 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8335324764251709,0.08427241281363991 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8430732011795044,0.10598132250080783 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8102875232696534,0.06785240970923799 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7909447312355041,0.0357998383419531 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.728659451007843,0.1510055827692834 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7383495092391967,0.15354239422184465 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7441934227943421,0.14510299893162049 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7461911797523498,0.15206960037108616 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.707374906539917,0.13949099620015099 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.715216588973999,0.12572558459422392 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7344660282135009,0.1532597362499129 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7344660282135009,0.1532597362499129 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7422330141067505,0.15286561154931766 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7445294976234436,0.06647358338082796 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7618371963500976,0.07919675178826276 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7693614721298218,0.12243737630362679 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7345593810081482,0.15308588823980654 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9070201635360717,0.050008354952921226 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9168035745620727,0.05006208021103692 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9031740188598633,0.04664949298680008 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8799290657043457,0.056332434236605756 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7694174766540527,0.1323815071230519 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8527072548866272,0.07904251187729652 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7442307472229004,0.1161515552566303 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7909260630607605,0.06553076283464754 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9206497311592102,0.03368011491063649 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9148431658744812,0.05045335343159241 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8935026168823242,0.044183222298514915 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9148244976997375,0.051266262018325175 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8004480957984924,0.10105237502062565 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8197908759117126,0.10335964519995125 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7887602806091308,0.11024879065148986 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7888723015785217,0.09988153208337541 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8703696846961975,0.0471714516114291 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8935399413108825,0.051785298523611724 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8876960396766662,0.05695455155578668 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9090179324150085,0.04638646140585552 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7716766119003295,0.06403842476682413 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8043315887451172,0.10021871247546439 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7580657124519348,0.04179659030318149 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7754854440689087,0.05010089869705153 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8993838667869568,0.05366630647725366 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9090365886688232,0.04422804449051182 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8800970792770386,0.03248058106941399 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.897386109828949,0.06404196586024248 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7713778972625732,0.10068096597030743 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.6945481896400452,0.09248709195080763 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7639282941818237,0.05428695970285378 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8043876051902771,0.0834650597020454 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9361277103424073,0.035877209791123854 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9418596029281616,0.03070254008522 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9341112732887268,0.03600795816372566 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9244772315025329,0.03837887778879082 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8219380140304565,0.07547754295301258 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8181292057037354,0.052562055516285774 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7811239719390869,0.09753130720436105 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8219006776809692,0.0716913735034855 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9380507826805115,0.03593940740715371 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9419716119766235,0.03800721488231152 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9437826752662659,0.03216472663543858 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.922591483592987,0.0317039707516288 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8605302453041077,0.07036372143431803 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8432598948478699,0.05269663690870983 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8121732711791992,0.0736431676387519 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8199402570724488,0.09423652060264057 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8780433177947998,0.0564165479424137 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8935026049613952,0.05568458051052992 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9031740188598633,0.05576189798952806 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8858289837837219,0.056037446313437426 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.6674757361412048,0.09169490778971937 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.694193434715271,0.08557650147462564 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.6998132944107056,0.11744573262109705 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7637416005134583,0.0929449030462506 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8896377921104431,0.05282179194098981 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8954816937446595,0.051186773095201005 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8915235280990601,0.0582622426178079 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8877147197723388,0.060320656148221234 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.725,0.12313650419874397 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7520350933074951,0.15877276470514273 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7327109813690186,0.12199309135987342 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7831777572631836,0.0721022173441679 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9419342756271363,0.02372215055505345 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9418782591819763,0.031867448198428926 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9360903739929199,0.03272020026942805 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9438200116157531,0.029652868370618597 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7752800583839417,0.14434017944423475 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8450709581375122,0.08195706604632562 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7462658643722534,0.09898601478136816 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8121172547340393,0.09245988109194513 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9341673016548157,0.02897582900826479 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.924533236026764,0.03192504056429232 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9322255373001098,0.03458014123465938 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9302837967872619,0.03543714159075129 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7696601867675781,0.05642929849512883 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7829723715782165,0.14510686275453138 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8006348013877869,0.03815952678573354 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8237864017486572,0.09158690473770653 with: {'activation_function': 'tanh', 'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8780993223190308,0.07677139450204679 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8760828852653504,0.04571524739995889 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.860511577129364,0.07867929140282606 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8818894743919372,0.06653372595994447 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8101381659507751,0.11016190424335986 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8141150116920471,0.07031215809287196 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7462285161018372,0.14515088044835567 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8238050937652588,0.07114525189121661 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8819454789161683,0.05953988058162016 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8876773715019226,0.05887452302306286 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8646004438400269,0.01226798246516416 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8877333760261535,0.044778262702939255 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7345967054367065,0.12683803935247645 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8142643928527832,0.06240330271776431 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7889469861984253,0.08191642315737163 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7560119390487671,0.07844787223608535 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9418596029281616,0.03418872564393154 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9477408647537231,0.03266031123696497 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9186519742012024,0.0413412083710897 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9380507707595825,0.037979689120989625 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8488424301147461,0.08250666269015508 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8702950000762939,0.06492783891601958 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8509522080421448,0.0753975273337994 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8703136682510376,0.06979511566257206 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.945817768573761,0.03259628544081518 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9400298714637756,0.03919065346550076 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9418782591819763,0.03302941224857309 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9380321145057678,0.03271022606564747 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8819641590118408,0.04683682379547804 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.907113516330719,0.055399760467156 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8567587852478027,0.05427048253892212 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8760642290115357,0.05819977249487991 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8722554087638855,0.07149121825974644 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8799477219581604,0.05726283671674983 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8780433058738708,0.05487994335729 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8760829091072082,0.06389519082720357 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7811613202095031,0.08791689097052331 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7502800464630127,0.08327670895482205 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7578790187835693,0.13722917945962584 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8044809699058533,0.07824802621861256 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8529686331748962,0.03375474624352226 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8684279322624207,0.07377160425723873 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8818894624710083,0.06334031039948058 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.881964135169983,0.03978052197709221 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.804443621635437,0.07352080652991919 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.779238247871399,0.10549798300380961 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7249439835548401,0.1211054595414237 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7949029207229614,0.03759159205516703 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9302651166915894,0.03645484874671696 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.939955186843872,0.03329285157856186 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.9400111913681031,0.03467896900541598 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9380134463310241,0.0327685523161918 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8645817756652832,0.0366167324024585 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8721060514450073,0.06927973345901353 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8317587733268738,0.026760344688386204 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8683905839920044,0.04481322965394698 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'uniform', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.9302651286125183,0.03696835946625779 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9496265888214112,0.029094398600769945 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 4}\n",
      "0.936146366596222,0.04025662833748423 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 2}\n",
      "0.9419156074523926,0.030543741325088098 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8607542872428894,0.03128621847531411 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.881852126121521,0.06316646800587677 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8413928270339965,0.05253518399928584 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8625093340873718,0.07194939194537084 with: {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e205a197",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "356fbb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "52/52 [==============================] - 1s 2ms/step - loss: 0.6700 - mse: 0.6700\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5470 - mse: 0.5470\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4474 - mse: 0.4474\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3767 - mse: 0.3767\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3157 - mse: 0.3157\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2725 - mse: 0.2725\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2485 - mse: 0.2485\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2347 - mse: 0.2347\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2220 - mse: 0.2220\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2138 - mse: 0.2138\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2012 - mse: 0.2012\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1992 - mse: 0.1992\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1769 - mse: 0.1769\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1736 - mse: 0.1736\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1630 - mse: 0.1630\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1504 - mse: 0.1504\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1503 - mse: 0.1503\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1370 - mse: 0.1370\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1438 - mse: 0.1438\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1272 - mse: 0.1272\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1204 - mse: 0.1204\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1162 - mse: 0.1162\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1103 - mse: 0.1103\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1015 - mse: 0.1015\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1033 - mse: 0.1033\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0914 - mse: 0.0914\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0946 - mse: 0.0946\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0857 - mse: 0.0857\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0854 - mse: 0.0854\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0841 - mse: 0.0841\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0831 - mse: 0.0831\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0767 - mse: 0.0767\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0706 - mse: 0.0706\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0693\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0746 - mse: 0.0746\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0724 - mse: 0.0724\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0638 - mse: 0.0638\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0603\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0632 - mse: 0.0632\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0716 - mse: 0.0716\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0615 - mse: 0.0615\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0686\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0619 - mse: 0.0619\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0625\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0628 - mse: 0.0628\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f506faad60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "final_model = Sequential()\n",
    "final_model.add(Dense(8, input_dim=28, kernel_initializer ='normal', activation='tanh'))\n",
    "final_model.add(Dropout(0.2))\n",
    "final_model.add(Dense(4, kernel_initializer='uniform', activation='softmax'))\n",
    "final_model.add(Dropout(0.2))\n",
    "final_model.add(Dense(1, kernel_initializer='uniform', activation='linear'))\n",
    "\n",
    "adam=adam_v2.Adam(learning_rate = 0.01)\n",
    "## compile model\n",
    "final_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "## fit the model \n",
    "final_model.fit(x_std,y, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74d3ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4998 - mse: 0.4998\n",
      "mse\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "score = final_model.evaluate(x,y)\n",
    "print((final_model.metrics_names[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122982a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
